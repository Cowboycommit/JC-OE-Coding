{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Ended Coding Analysis\n",
    "\n",
    "This notebook provides a comprehensive framework for analyzing open-ended qualitative data through:\n",
    "- **Code Frames**: Systematic coding structures for categorizing data\n",
    "- **Themes**: Identification and analysis of recurring patterns\n",
    "- **Categorization**: Multi-level classification and organization of qualitative data\n",
    "\n",
    "## Features\n",
    "- Data loading from flat files (CSV, Excel) and databases (SQLite, PostgreSQL)\n",
    "- Interactive visualizations\n",
    "- Robust error handling\n",
    "- Code quality checks via Makefile\n",
    "- Comprehensive testing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import logging\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database connections\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# NLP and text analysis\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Module\n",
    "\n",
    "Robust data loading from multiple sources with comprehensive error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Handles data loading from various sources with error handling.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def load_csv(self, filepath: str, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from CSV file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to CSV file\n",
    "            **kwargs: Additional arguments for pd.read_csv\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with loaded data\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If file doesn't exist\n",
    "            pd.errors.EmptyDataError: If file is empty\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(filepath):\n",
    "                raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "            \n",
    "            df = pd.read_csv(filepath, **kwargs)\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from {filepath}\")\n",
    "            return df\n",
    "        \n",
    "        except pd.errors.EmptyDataError:\n",
    "            self.logger.error(f\"Empty file: {filepath}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading CSV {filepath}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_excel(self, filepath: str, sheet_name: Union[str, int] = 0, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from Excel file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to Excel file\n",
    "            sheet_name: Sheet name or index\n",
    "            **kwargs: Additional arguments for pd.read_excel\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with loaded data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(filepath):\n",
    "                raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "            \n",
    "            df = pd.read_excel(filepath, sheet_name=sheet_name, **kwargs)\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from {filepath}\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading Excel {filepath}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_from_sqlite(self, db_path: str, query: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from SQLite database.\n",
    "        \n",
    "        Args:\n",
    "            db_path: Path to SQLite database file\n",
    "            query: SQL query to execute\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with query results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            conn.close()\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from SQLite database\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading from SQLite: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_from_postgres(self, connection_string: str, query: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from PostgreSQL database.\n",
    "        \n",
    "        Args:\n",
    "            connection_string: PostgreSQL connection string\n",
    "            query: SQL query to execute\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with query results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            engine = create_engine(connection_string)\n",
    "            df = pd.read_sql_query(query, engine)\n",
    "            engine.dispose()\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from PostgreSQL database\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading from PostgreSQL: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader()\n",
    "print(\"\u2713 DataLoader initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sample Data\n",
    "\n",
    "Load your qualitative data from various sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load from CSV\n",
    "try:\n",
    "    # Replace with your actual data file\n",
    "    if os.path.exists('data/sample_responses.csv'):\n",
    "        df = data_loader.load_csv('data/sample_responses.csv')\n",
    "    else:\n",
    "        # Create sample data for demonstration\n",
    "        df = pd.DataFrame({\n",
    "            'id': range(1, 21),\n",
    "            'response': [\n",
    "                'I love the flexibility of remote work',\n",
    "                'Better work-life balance is crucial',\n",
    "                'Communication challenges with team members',\n",
    "                'Increased productivity at home',\n",
    "                'Missing social interactions with colleagues',\n",
    "                'Technology issues affect my work',\n",
    "                'More time for family and personal activities',\n",
    "                'Difficulty separating work and personal life',\n",
    "                'Cost savings from not commuting',\n",
    "                'Feeling isolated from the team',\n",
    "                'Flexible schedule allows better time management',\n",
    "                'Video call fatigue is real',\n",
    "                'Can focus better without office distractions',\n",
    "                'Miss casual conversations at the office',\n",
    "                'Home office setup improves comfort',\n",
    "                'Internet connectivity problems',\n",
    "                'Appreciate the autonomy',\n",
    "                'Harder to build relationships remotely',\n",
    "                'Reduced stress from commuting',\n",
    "                'Challenging to stay motivated alone'\n",
    "            ],\n",
    "            'respondent_id': [f'R{i:03d}' for i in range(1, 21)],\n",
    "            'timestamp': pd.date_range(start='2024-01-01', periods=20, freq='D')\n",
    "        })\n",
    "        logger.info(\"Using sample demonstration data\")\n",
    "    \n",
    "    print(f\"\\nLoaded {len(df)} responses\")\n",
    "    print(f\"\\nData shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    display(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code Frames\n",
    "\n",
    "Code frames provide a structured approach to categorizing qualitative data. Define your coding scheme here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeFrame:\n",
    "    \"\"\"Manages coding frames for qualitative analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, description: str = \"\"):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.codes = {}\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def add_code(self, code_id: str, label: str, description: str = \"\", \n",
    "                 keywords: Optional[List[str]] = None, parent: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Add a code to the frame.\n",
    "        \n",
    "        Args:\n",
    "            code_id: Unique identifier for the code\n",
    "            label: Human-readable label\n",
    "            description: Detailed description of the code\n",
    "            keywords: List of keywords associated with this code\n",
    "            parent: Parent code ID for hierarchical structures\n",
    "        \"\"\"\n",
    "        self.codes[code_id] = {\n",
    "            'label': label,\n",
    "            'description': description,\n",
    "            'keywords': keywords or [],\n",
    "            'parent': parent,\n",
    "            'count': 0\n",
    "        }\n",
    "        self.logger.info(f\"Added code: {code_id} - {label}\")\n",
    "    \n",
    "    def apply_codes(self, text: str, case_sensitive: bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Apply codes to text based on keyword matching.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to code\n",
    "            case_sensitive: Whether to use case-sensitive matching\n",
    "            \n",
    "        Returns:\n",
    "            List of matching code IDs\n",
    "        \"\"\"\n",
    "        if not case_sensitive:\n",
    "            text = text.lower()\n",
    "        \n",
    "        matched_codes = []\n",
    "        for code_id, code_info in self.codes.items():\n",
    "            keywords = code_info['keywords']\n",
    "            if not case_sensitive:\n",
    "                keywords = [k.lower() for k in keywords]\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                if keyword in text:\n",
    "                    matched_codes.append(code_id)\n",
    "                    self.codes[code_id]['count'] += 1\n",
    "                    break\n",
    "        \n",
    "        return matched_codes\n",
    "    \n",
    "    def get_hierarchy(self) -> Dict:\n",
    "        \"\"\"Get hierarchical structure of codes.\"\"\"\n",
    "        hierarchy = defaultdict(list)\n",
    "        for code_id, code_info in self.codes.items():\n",
    "            parent = code_info.get('parent')\n",
    "            if parent:\n",
    "                hierarchy[parent].append(code_id)\n",
    "            else:\n",
    "                hierarchy['root'].append(code_id)\n",
    "        return dict(hierarchy)\n",
    "    \n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate summary statistics of code usage.\"\"\"\n",
    "        summary_data = []\n",
    "        for code_id, code_info in self.codes.items():\n",
    "            summary_data.append({\n",
    "                'Code ID': code_id,\n",
    "                'Label': code_info['label'],\n",
    "                'Count': code_info['count'],\n",
    "                'Parent': code_info.get('parent', 'None')\n",
    "            })\n",
    "        return pd.DataFrame(summary_data).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"\u2713 CodeFrame class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define Your Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code frame for analyzing remote work experiences\n",
    "remote_work_frame = CodeFrame(\n",
    "    name=\"Remote Work Analysis\",\n",
    "    description=\"Coding frame for analyzing remote work experiences\"\n",
    ")\n",
    "\n",
    "# Define main categories (top-level codes)\n",
    "remote_work_frame.add_code(\n",
    "    'POSITIVE',\n",
    "    'Positive Experiences',\n",
    "    'Positive aspects of remote work'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEGATIVE',\n",
    "    'Negative Experiences',\n",
    "    'Challenges and negative aspects of remote work'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEUTRAL',\n",
    "    'Neutral/Mixed',\n",
    "    'Neutral or mixed experiences'\n",
    ")\n",
    "\n",
    "# Define sub-codes for positive experiences\n",
    "remote_work_frame.add_code(\n",
    "    'POS_FLEX',\n",
    "    'Flexibility',\n",
    "    'Flexibility in schedule and location',\n",
    "    keywords=['flexibility', 'flexible', 'autonomy', 'schedule'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_BALANCE',\n",
    "    'Work-Life Balance',\n",
    "    'Improved work-life balance',\n",
    "    keywords=['work-life balance', 'family', 'personal activities', 'time management'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_PROD',\n",
    "    'Productivity',\n",
    "    'Increased productivity',\n",
    "    keywords=['productivity', 'productive', 'focus', 'efficient'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_COST',\n",
    "    'Cost Savings',\n",
    "    'Financial benefits',\n",
    "    keywords=['cost savings', 'commuting', 'save money', 'reduced stress'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "# Define sub-codes for negative experiences\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_COMM',\n",
    "    'Communication Issues',\n",
    "    'Communication and collaboration challenges',\n",
    "    keywords=['communication', 'challenges', 'video call', 'fatigue'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_SOCIAL',\n",
    "    'Social Isolation',\n",
    "    'Lack of social interaction',\n",
    "    keywords=['isolated', 'social', 'miss', 'lonely', 'relationships'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_TECH',\n",
    "    'Technical Issues',\n",
    "    'Technology and infrastructure problems',\n",
    "    keywords=['technology', 'internet', 'connectivity', 'technical'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_BOUND',\n",
    "    'Work-Life Boundaries',\n",
    "    'Difficulty maintaining boundaries',\n",
    "    keywords=['separating', 'boundaries', 'motivated', 'personal life'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame '{remote_work_frame.name}' created with {len(remote_work_frame.codes)} codes\")\n",
    "print(f\"\\nHierarchy: {remote_work_frame.get_hierarchy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Apply Codes to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes to each response\n",
    "df['codes'] = df['response'].apply(\n",
    "    lambda x: remote_work_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "# Create binary columns for each code\n",
    "for code_id in remote_work_frame.codes.keys():\n",
    "    df[f'code_{code_id}'] = df['codes'].apply(lambda x: 1 if code_id in x else 0)\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df[['response', 'codes']].head(10))\n",
    "\n",
    "# Show code summary\n",
    "print(\"\\nCode Summary:\")\n",
    "code_summary = remote_work_frame.summary()\n",
    "display(code_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualize Code Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of code frequencies\n",
    "fig = px.bar(\n",
    "    code_summary,\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Code Distribution in Responses',\n",
    "    labels={'Label': 'Code', 'Count': 'Frequency'},\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Hierarchical sunburst chart\n",
    "sunburst_data = []\n",
    "for code_id, code_info in remote_work_frame.codes.items():\n",
    "    parent = code_info.get('parent', '')\n",
    "    sunburst_data.append({\n",
    "        'labels': code_info['label'],\n",
    "        'parents': remote_work_frame.codes[parent]['label'] if parent else '',\n",
    "        'values': code_info['count']\n",
    "    })\n",
    "\n",
    "sunburst_df = pd.DataFrame(sunburst_data)\n",
    "fig = px.sunburst(\n",
    "    sunburst_df,\n",
    "    names='labels',\n",
    "    parents='parents',\n",
    "    values='values',\n",
    "    title='Hierarchical Code Structure'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Themes\n",
    "\n",
    "Identify and analyze recurring themes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThemeAnalyzer:\n",
    "    \"\"\"Analyzes and identifies themes in qualitative data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.themes = {}\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def define_theme(self, theme_id: str, name: str, description: str, \n",
    "                    associated_codes: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Define a theme.\n",
    "        \n",
    "        Args:\n",
    "            theme_id: Unique identifier\n",
    "            name: Theme name\n",
    "            description: Detailed description\n",
    "            associated_codes: List of code IDs associated with this theme\n",
    "        \"\"\"\n",
    "        self.themes[theme_id] = {\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'codes': associated_codes or [],\n",
    "            'responses': []\n",
    "        }\n",
    "        self.logger.info(f\"Defined theme: {theme_id} - {name}\")\n",
    "    \n",
    "    def identify_themes(self, df: pd.DataFrame, code_column: str = 'codes') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Identify themes in coded data.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with coded responses\n",
    "            code_column: Column name containing codes\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with theme assignments\n",
    "        \"\"\"\n",
    "        theme_assignments = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            response_codes = set(row[code_column])\n",
    "            matched_themes = []\n",
    "            \n",
    "            for theme_id, theme_info in self.themes.items():\n",
    "                theme_codes = set(theme_info['codes'])\n",
    "                if response_codes & theme_codes:  # Intersection\n",
    "                    matched_themes.append(theme_id)\n",
    "                    self.themes[theme_id]['responses'].append(idx)\n",
    "            \n",
    "            theme_assignments.append(matched_themes)\n",
    "        \n",
    "        df['themes'] = theme_assignments\n",
    "        return df\n",
    "    \n",
    "    def theme_co_occurrence(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate co-occurrence matrix of themes.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with theme co-occurrence counts\n",
    "        \"\"\"\n",
    "        theme_ids = list(self.themes.keys())\n",
    "        n_themes = len(theme_ids)\n",
    "        co_occurrence = np.zeros((n_themes, n_themes))\n",
    "        \n",
    "        # Count co-occurrences\n",
    "        for theme_info in self.themes.values():\n",
    "            responses = theme_info['responses']\n",
    "            # This is simplified - you'd check actual response overlaps\n",
    "        \n",
    "        return pd.DataFrame(\n",
    "            co_occurrence,\n",
    "            index=[self.themes[t]['name'] for t in theme_ids],\n",
    "            columns=[self.themes[t]['name'] for t in theme_ids]\n",
    "        )\n",
    "    \n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate theme summary statistics.\"\"\"\n",
    "        summary_data = []\n",
    "        for theme_id, theme_info in self.themes.items():\n",
    "            summary_data.append({\n",
    "                'Theme ID': theme_id,\n",
    "                'Name': theme_info['name'],\n",
    "                'Description': theme_info['description'],\n",
    "                'Associated Codes': len(theme_info['codes']),\n",
    "                'Frequency': len(theme_info['responses'])\n",
    "            })\n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\u2713 ThemeAnalyzer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Define Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize theme analyzer\n",
    "theme_analyzer = ThemeAnalyzer()\n",
    "\n",
    "# Define themes based on code patterns\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_AUTONOMY',\n",
    "    'Autonomy and Control',\n",
    "    'Themes related to personal autonomy, control over schedule, and independence',\n",
    "    associated_codes=['POS_FLEX', 'POS_BALANCE']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_PERFORMANCE',\n",
    "    'Work Performance',\n",
    "    'Themes related to productivity, efficiency, and work output',\n",
    "    associated_codes=['POS_PROD', 'NEG_TECH']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_CONNECTION',\n",
    "    'Social Connection',\n",
    "    'Themes related to social interaction, relationships, and collaboration',\n",
    "    associated_codes=['NEG_SOCIAL', 'NEG_COMM']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_WELLBEING',\n",
    "    'Personal Wellbeing',\n",
    "    'Themes related to mental health, stress, and life quality',\n",
    "    associated_codes=['POS_COST', 'POS_BALANCE', 'NEG_BOUND']\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Defined {len(theme_analyzer.themes)} themes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Identify Themes in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply theme identification\n",
    "df = theme_analyzer.identify_themes(df)\n",
    "\n",
    "print(\"\\nResponses with Identified Themes:\")\n",
    "display(df[['response', 'codes', 'themes']].head(10))\n",
    "\n",
    "# Show theme summary\n",
    "print(\"\\nTheme Summary:\")\n",
    "theme_summary = theme_analyzer.summary()\n",
    "display(theme_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme frequency bar chart\n",
    "fig = px.bar(\n",
    "    theme_summary,\n",
    "    x='Name',\n",
    "    y='Frequency',\n",
    "    title='Theme Distribution',\n",
    "    color='Frequency',\n",
    "    color_continuous_scale='Viridis',\n",
    "    hover_data=['Description']\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Theme network visualization\n",
    "# Count theme co-occurrences\n",
    "theme_counts = Counter()\n",
    "theme_pairs = Counter()\n",
    "\n",
    "for themes in df['themes']:\n",
    "    for theme in themes:\n",
    "        theme_counts[theme] += 1\n",
    "    \n",
    "    # Count pairs\n",
    "    for i, theme1 in enumerate(themes):\n",
    "        for theme2 in themes[i+1:]:\n",
    "            pair = tuple(sorted([theme1, theme2]))\n",
    "            theme_pairs[pair] += 1\n",
    "\n",
    "print(\"\\nTheme Co-occurrences:\")\n",
    "for pair, count in theme_pairs.most_common():\n",
    "    print(f\"{pair[0]} <-> {pair[1]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorization\n",
    "\n",
    "Advanced categorization and classification of coded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryManager:\n",
    "    \"\"\"Manages multi-level categorization of qualitative data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.categories = {}\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def create_category(self, category_id: str, name: str, \n",
    "                       criteria: Dict, level: int = 1):\n",
    "        \"\"\"\n",
    "        Create a category.\n",
    "        \n",
    "        Args:\n",
    "            category_id: Unique identifier\n",
    "            name: Category name\n",
    "            criteria: Dictionary defining categorization criteria\n",
    "            level: Hierarchical level (1 = top level)\n",
    "        \"\"\"\n",
    "        self.categories[category_id] = {\n",
    "            'name': name,\n",
    "            'criteria': criteria,\n",
    "            'level': level,\n",
    "            'count': 0\n",
    "        }\n",
    "        self.logger.info(f\"Created category: {category_id} - {name} (Level {level})\")\n",
    "    \n",
    "    def categorize(self, df: pd.DataFrame, \n",
    "                   code_columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply categorization to DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to categorize\n",
    "            code_columns: List of code column names to consider\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with category assignments\n",
    "        \"\"\"\n",
    "        categories_assigned = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            assigned = []\n",
    "            \n",
    "            for cat_id, cat_info in self.categories.items():\n",
    "                if self._meets_criteria(row, cat_info['criteria']):\n",
    "                    assigned.append(cat_id)\n",
    "                    self.categories[cat_id]['count'] += 1\n",
    "            \n",
    "            categories_assigned.append(assigned)\n",
    "        \n",
    "        df['categories'] = categories_assigned\n",
    "        return df\n",
    "    \n",
    "    def _meets_criteria(self, row: pd.Series, criteria: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a row meets category criteria.\n",
    "        \n",
    "        Args:\n",
    "            row: DataFrame row\n",
    "            criteria: Criteria dictionary\n",
    "            \n",
    "        Returns:\n",
    "            True if criteria are met\n",
    "        \"\"\"\n",
    "        for key, value in criteria.items():\n",
    "            if key == 'codes_required':\n",
    "                # Check if any required codes are present\n",
    "                if not any(code in row.get('codes', []) for code in value):\n",
    "                    return False\n",
    "            \n",
    "            elif key == 'codes_all':\n",
    "                # Check if all codes are present\n",
    "                if not all(code in row.get('codes', []) for code in value):\n",
    "                    return False\n",
    "            \n",
    "            elif key == 'themes_required':\n",
    "                # Check if any required themes are present\n",
    "                if not any(theme in row.get('themes', []) for theme in value):\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate category summary.\"\"\"\n",
    "        summary_data = []\n",
    "        for cat_id, cat_info in self.categories.items():\n",
    "            summary_data.append({\n",
    "                'Category ID': cat_id,\n",
    "                'Name': cat_info['name'],\n",
    "                'Level': cat_info['level'],\n",
    "                'Count': cat_info['count']\n",
    "            })\n",
    "        return pd.DataFrame(summary_data).sort_values('Level')\n",
    "    \n",
    "    def cross_tabulation(self, df: pd.DataFrame, \n",
    "                        category1: str, category2: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create cross-tabulation between categories.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with categories\n",
    "            category1: First category ID\n",
    "            category2: Second category ID\n",
    "            \n",
    "        Returns:\n",
    "            Cross-tabulation DataFrame\n",
    "        \"\"\"\n",
    "        # Create binary indicators\n",
    "        df[f'has_{category1}'] = df['categories'].apply(\n",
    "            lambda x: 1 if category1 in x else 0\n",
    "        )\n",
    "        df[f'has_{category2}'] = df['categories'].apply(\n",
    "            lambda x: 1 if category2 in x else 0\n",
    "        )\n",
    "        \n",
    "        return pd.crosstab(\n",
    "            df[f'has_{category1}'],\n",
    "            df[f'has_{category2}'],\n",
    "            rownames=[self.categories[category1]['name']],\n",
    "            colnames=[self.categories[category2]['name']]\n",
    "        )\n",
    "\n",
    "print(\"\u2713 CategoryManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Define Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize category manager\n",
    "category_manager = CategoryManager()\n",
    "\n",
    "# Level 1: Primary sentiment\n",
    "category_manager.create_category(\n",
    "    'CAT_POSITIVE',\n",
    "    'Overall Positive',\n",
    "    {'codes_required': ['POS_FLEX', 'POS_BALANCE', 'POS_PROD', 'POS_COST']},\n",
    "    level=1\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_NEGATIVE',\n",
    "    'Overall Negative',\n",
    "    {'codes_required': ['NEG_COMM', 'NEG_SOCIAL', 'NEG_TECH', 'NEG_BOUND']},\n",
    "    level=1\n",
    ")\n",
    "\n",
    "# Level 2: Specific aspects\n",
    "category_manager.create_category(\n",
    "    'CAT_WORK_FOCUSED',\n",
    "    'Work-Focused',\n",
    "    {'codes_required': ['POS_PROD', 'NEG_TECH', 'NEG_COMM']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_LIFE_FOCUSED',\n",
    "    'Life-Focused',\n",
    "    {'codes_required': ['POS_BALANCE', 'POS_COST', 'NEG_BOUND']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_SOCIAL_FOCUSED',\n",
    "    'Social-Focused',\n",
    "    {'codes_required': ['NEG_SOCIAL', 'NEG_COMM']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Created {len(category_manager.categories)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Apply Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply categories to data\n",
    "df = category_manager.categorize(df)\n",
    "\n",
    "print(\"\\nCategorized Responses:\")\n",
    "display(df[['response', 'codes', 'themes', 'categories']].head(10))\n",
    "\n",
    "# Show category summary\n",
    "print(\"\\nCategory Summary:\")\n",
    "category_summary = category_manager.summary()\n",
    "display(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualize Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution by level\n",
    "fig = px.bar(\n",
    "    category_summary,\n",
    "    x='Name',\n",
    "    y='Count',\n",
    "    color='Level',\n",
    "    title='Category Distribution by Hierarchical Level',\n",
    "    barmode='group'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Pie chart of primary categories\n",
    "level1_cats = category_summary[category_summary['Level'] == 1]\n",
    "fig = px.pie(\n",
    "    level1_cats,\n",
    "    values='Count',\n",
    "    names='Name',\n",
    "    title='Primary Category Distribution'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Analysis & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisReporter:\n",
    "    \"\"\"Generates comprehensive analysis reports.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, code_frame: CodeFrame, \n",
    "                 theme_analyzer: ThemeAnalyzer, category_manager: CategoryManager):\n",
    "        self.df = df\n",
    "        self.code_frame = code_frame\n",
    "        self.theme_analyzer = theme_analyzer\n",
    "        self.category_manager = category_manager\n",
    "    \n",
    "    def generate_summary_stats(self) -> Dict:\n",
    "        \"\"\"Generate summary statistics.\"\"\"\n",
    "        stats = {\n",
    "            'total_responses': len(self.df),\n",
    "            'total_codes': len(self.code_frame.codes),\n",
    "            'total_themes': len(self.theme_analyzer.themes),\n",
    "            'total_categories': len(self.category_manager.categories),\n",
    "            'avg_codes_per_response': self.df['codes'].apply(len).mean(),\n",
    "            'avg_themes_per_response': self.df['themes'].apply(len).mean(),\n",
    "            'avg_categories_per_response': self.df['categories'].apply(len).mean()\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    def create_dashboard(self):\n",
    "        \"\"\"Create interactive dashboard.\"\"\"\n",
    "        from plotly.subplots import make_subplots\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'Code Distribution',\n",
    "                'Theme Distribution',\n",
    "                'Category Distribution',\n",
    "                'Coverage Statistics'\n",
    "            ),\n",
    "            specs=[\n",
    "                [{'type': 'bar'}, {'type': 'bar'}],\n",
    "                [{'type': 'bar'}, {'type': 'indicator'}]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Code distribution\n",
    "        code_summary = self.code_frame.summary()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=code_summary['Label'], y=code_summary['Count'], name='Codes'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Theme distribution\n",
    "        theme_summary = self.theme_analyzer.summary()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=theme_summary['Name'], y=theme_summary['Frequency'], name='Themes'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Category distribution\n",
    "        category_summary = self.category_manager.summary()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=category_summary['Name'], y=category_summary['Count'], name='Categories'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Coverage indicator\n",
    "        stats = self.generate_summary_stats()\n",
    "        fig.add_trace(\n",
    "            go.Indicator(\n",
    "                mode=\"number+delta\",\n",
    "                value=stats['avg_codes_per_response'],\n",
    "                title={\"text\": \"Avg Codes/Response\"},\n",
    "                delta={'reference': 1}\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=800, showlegend=False, title_text=\"Open-Ended Coding Analysis Dashboard\")\n",
    "        return fig\n",
    "\n",
    "# Create reporter\n",
    "reporter = AnalysisReporter(df, remote_work_frame, theme_analyzer, category_manager)\n",
    "\n",
    "# Generate summary statistics\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "stats = reporter.generate_summary_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value:.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "\n",
    "# Display dashboard\n",
    "print(\"\\n=== Analysis Dashboard ===\")\n",
    "dashboard = reporter.create_dashboard()\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export coded data\n",
    "output_file = output_dir / 'coded_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\u2713 Exported coded data to {output_file}\")\n",
    "\n",
    "# Export code summary\n",
    "code_summary = remote_work_frame.summary()\n",
    "code_summary.to_csv(output_dir / 'code_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported code summary to {output_dir / 'code_summary.csv'}\")\n",
    "\n",
    "# Export theme summary\n",
    "theme_summary = theme_analyzer.summary()\n",
    "theme_summary.to_csv(output_dir / 'theme_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported theme summary to {output_dir / 'theme_summary.csv'}\")\n",
    "\n",
    "# Export category summary\n",
    "category_summary = category_manager.summary()\n",
    "category_summary.to_csv(output_dir / 'category_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported category summary to {output_dir / 'category_summary.csv'}\")\n",
    "\n",
    "print(\"\\n\u2713 All results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# PART 2: Additional Dataset Analyses\n\nThe following sections demonstrate the framework with four additional datasets covering different research domains.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Political Leadership Analysis (Trump Dataset)\n\n",
    "Analyze political discourse, policy impacts, and public opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trump dataset\n",
    "df_trump = data_loader.load_csv('data/trump_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_trump)} responses\")\n",
    "print(f\"Data shape: {df_trump.shape}\")\n",
    "print(f\"Columns: {df_trump.columns.tolist()}\")\n",
    "display(df_trump.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Define Political Discourse Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for political discourse analysis\n",
    "trump_frame = CodeFrame(\n",
    "    name=\"Political Leadership Analysis\",\n",
    "    description=\"Code frame for analyzing political discourse and policy impacts\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "trump_frame.add_code('POLICY', 'Policy Analysis', 'Discussion of policies and their impacts')\n",
    "trump_frame.add_code('COMMUNICATION', 'Communication Style', 'Communication and rhetoric')\n",
    "trump_frame.add_code('GOVERNANCE', 'Governance', 'Leadership and governance approach')\n",
    "trump_frame.add_code('IMPACT', 'Political Impact', 'Political and social impacts')\n",
    "\n",
    "# Policy sub-codes\n",
    "trump_frame.add_code(\n",
    "    'POL_ECONOMY',\n",
    "    'Economic Policy',\n",
    "    'Trade, taxation, and economic impacts',\n",
    "    keywords=['trade', 'economy', 'economic', 'tax', 'taxation', 'business', 'corporate'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'POL_FOREIGN',\n",
    "    'Foreign Policy',\n",
    "    'International relations and foreign policy',\n",
    "    keywords=['foreign', 'international', 'nato', 'russia', 'china', 'diplomatic', 'agreements'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'POL_DOMESTIC',\n",
    "    'Domestic Policy',\n",
    "    'Immigration, healthcare, and domestic issues',\n",
    "    keywords=['immigration', 'healthcare', 'border', 'wall', 'domestic', 'reform'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'POL_JUDICIARY',\n",
    "    'Judicial Appointments',\n",
    "    'Court appointments and judicial impact',\n",
    "    keywords=['court', 'supreme', 'judicial', 'judges', 'appointments', 'nominees'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "# Communication sub-codes\n",
    "trump_frame.add_code(\n",
    "    'COMM_MEDIA',\n",
    "    'Media Relations',\n",
    "    'Relationship with media and press coverage',\n",
    "    keywords=['media', 'press', 'coverage', 'fake news', 'adversarial'],\n",
    "    parent='COMMUNICATION'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'COMM_SOCIAL',\n",
    "    'Social Media',\n",
    "    'Twitter and social media usage',\n",
    "    keywords=['twitter', 'social media', 'tweets', 'unprecedented'],\n",
    "    parent='COMMUNICATION'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'COMM_RHETORIC',\n",
    "    'Political Rhetoric',\n",
    "    'Speaking style and political rhetoric',\n",
    "    keywords=['rhetoric', 'communication', 'style', 'unconventional', 'theatrical'],\n",
    "    parent='COMMUNICATION'\n",
    ")\n",
    "\n",
    "# Governance sub-codes\n",
    "trump_frame.add_code(\n",
    "    'GOV_LEADERSHIP',\n",
    "    'Leadership Style',\n",
    "    'Management and leadership approach',\n",
    "    keywords=['leadership', 'governance', 'management', 'approach', 'business'],\n",
    "    parent='GOVERNANCE'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'GOV_LOYALTY',\n",
    "    'Loyalty Dynamics',\n",
    "    'Loyalty expectations and demands',\n",
    "    keywords=['loyalty', 'demands', 'officials', 'unusual'],\n",
    "    parent='GOVERNANCE'\n",
    ")\n",
    "\n",
    "# Impact sub-codes\n",
    "trump_frame.add_code(\n",
    "    'IMP_VOTERS',\n",
    "    'Voter Impact',\n",
    "    'Impact on voter demographics and base',\n",
    "    keywords=['voters', 'base', 'demographics', 'energized', 'working-class', 'consistent'],\n",
    "    parent='IMPACT'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'IMP_POLITICAL',\n",
    "    'Political System Impact',\n",
    "    'Impact on political system and norms',\n",
    "    keywords=['impeachment', 'divisive', 'proceedings', 'political', 'pardons'],\n",
    "    parent='IMPACT'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'IMP_LASTING',\n",
    "    'Long-term Impact',\n",
    "    'Lasting effects and legacy',\n",
    "    keywords=['lasting', 'impact', 'legacy', 'long-term', 'shift'],\n",
    "    parent='IMPACT'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(trump_frame.codes)} codes\")\n",
    "print(f\"Hierarchy: {trump_frame.get_hierarchy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_trump['codes'] = df_trump['response'].apply(\n",
    "    lambda x: trump_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_trump[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "trump_summary = trump_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(trump_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    trump_summary[trump_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Political Discourse Code Distribution',\n",
    "    color_continuous_scale='Reds'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Justice System Analysis (Epstein Dataset)\n\n",
    "Analyze institutional accountability and justice system issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Epstein dataset\n",
    "df_epstein = data_loader.load_csv('data/epstein_case_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_epstein)} responses\")\n",
    "print(f\"Data shape: {df_epstein.shape}\")\n",
    "display(df_epstein.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Define Justice System Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for justice system analysis\n",
    "epstein_frame = CodeFrame(\n",
    "    name=\"Justice System Analysis\",\n",
    "    description=\"Code frame for institutional accountability and justice system issues\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "epstein_frame.add_code('INSTITUTIONAL', 'Institutional Issues', 'Institutional failures and oversight')\n",
    "epstein_frame.add_code('LEGAL', 'Legal Process', 'Legal proceedings and justice system')\n",
    "epstein_frame.add_code('SOCIAL', 'Social Impact', 'Social and cultural implications')\n",
    "epstein_frame.add_code('REFORM', 'Reform Needs', 'Calls for reform and change')\n",
    "\n",
    "# Institutional sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'INST_OVERSIGHT',\n",
    "    'Oversight Failures',\n",
    "    'Failures in institutional oversight',\n",
    "    keywords=['oversight', 'failures', 'institutional', 'monitoring', 'procedures'],\n",
    "    parent='INSTITUTIONAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'INST_ACCOUNTABILITY',\n",
    "    'Accountability Issues',\n",
    "    'Questions of accountability and responsibility',\n",
    "    keywords=['accountability', 'responsible', 'connections', 'powerful', 'enablers'],\n",
    "    parent='INSTITUTIONAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'INST_PRIVILEGE',\n",
    "    'Privilege and Power',\n",
    "    'Role of wealth and privilege',\n",
    "    keywords=['privilege', 'wealth', 'power', 'preferential', 'treatment', 'factor'],\n",
    "    parent='INSTITUTIONAL'\n",
    ")\n",
    "\n",
    "# Legal process sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'LEG_JUSTICE',\n",
    "    'Justice System',\n",
    "    'Justice system handling and equal treatment',\n",
    "    keywords=['justice', 'equal', 'treatment', 'handling', 'system'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'LEG_PROCESS',\n",
    "    'Legal Process',\n",
    "    'Plea deals and prosecutorial decisions',\n",
    "    keywords=['plea', 'deal', 'prosecution', 'legal', 'decisions', 'prior'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'LEG_CUSTODY',\n",
    "    'Custody Issues',\n",
    "    'Death in custody and prison procedures',\n",
    "    keywords=['custody', 'death', 'prison', 'jail', 'procedures'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'LEG_INVESTIGATION',\n",
    "    'Investigations',\n",
    "    'Federal investigations and inquiries',\n",
    "    keywords=['investigation', 'federal', 'revealed', 'inquiries', 'pressure'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "# Social impact sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'SOC_VICTIMS',\n",
    "    'Victim Advocacy',\n",
    "    'Focus on victims and survivors',\n",
    "    keywords=['victims', 'survivors', 'believing', 'advocates', 'impact', 'support', 'compensation'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'SOC_TRUST',\n",
    "    'Public Trust',\n",
    "    'Impact on public trust in institutions',\n",
    "    keywords=['trust', 'public', 'damaged', 'confidence'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'SOC_AWARENESS',\n",
    "    'Social Awareness',\n",
    "    'Raising awareness about systemic issues',\n",
    "    keywords=['trafficking', 'problem', 'societal', 'awareness', 'attention'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'SOC_MEDIA',\n",
    "    'Media Role',\n",
    "    'Role of journalism and media coverage',\n",
    "    keywords=['media', 'journalism', 'coverage', 'reporting', 'sensitive'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "# Reform sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'REF_LEGAL',\n",
    "    'Legal Reforms',\n",
    "    'Proposed legal and justice reforms',\n",
    "    keywords=['reform', 'proposed', 'prevent', 'criminal justice', 'transparency'],\n",
    "    parent='REFORM'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'REF_PROTECTION',\n",
    "    'Protection Systems',\n",
    "    'Need for better protection of vulnerable individuals',\n",
    "    keywords=['protection', 'vulnerable', 'inadequate', 'background', 'checks'],\n",
    "    parent='REFORM'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(epstein_frame.codes)} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_epstein['codes'] = df_epstein['response'].apply(\n",
    "    lambda x: epstein_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_epstein[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "epstein_summary = epstein_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(epstein_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    epstein_summary[epstein_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Justice System Code Distribution',\n",
    "    color_continuous_scale='Oranges'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cricket Analysis (Sports Dataset)\n\n",
    "Analyze cricket perspectives, formats, and cultural impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cricket dataset\n",
    "df_cricket = data_loader.load_csv('data/cricket_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_cricket)} responses\")\n",
    "print(f\"Data shape: {df_cricket.shape}\")\n",
    "display(df_cricket.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Define Cricket Analysis Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for cricket analysis\n",
    "cricket_frame = CodeFrame(\n",
    "    name=\"Cricket Analysis\",\n",
    "    description=\"Code frame for analyzing cricket perspectives and culture\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "cricket_frame.add_code('FORMATS', 'Cricket Formats', 'Different formats and competitions')\n",
    "cricket_frame.add_code('TECHNICAL', 'Technical Aspects', 'Skills, strategies, and techniques')\n",
    "cricket_frame.add_code('CULTURE', 'Cricket Culture', 'Cultural and social aspects')\n",
    "cricket_frame.add_code('DEVELOPMENT', 'Game Development', 'Evolution and modernization')\n",
    "\n",
    "# Format sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'FMT_TEST',\n",
    "    'Test Cricket',\n",
    "    'Test matches and traditional format',\n",
    "    keywords=['test', 'purest', 'ashes', 'resilience', 'strategy'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'FMT_T20',\n",
    "    'T20 Format',\n",
    "    'T20 cricket and innovations',\n",
    "    keywords=['t20', 'ipl', 'big bash', 'accessible', 'entertainment', 'innovations'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'FMT_LEAGUES',\n",
    "    'Leagues and Competitions',\n",
    "    'IPL, county championship, and leagues',\n",
    "    keywords=['league', 'ipl', 'county', 'championship', 'big bash', 'hundred'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'FMT_TOURNAMENTS',\n",
    "    'Major Tournaments',\n",
    "    'World Cup and major tournaments',\n",
    "    keywords=['world cup', 'tournament', 'pinnacle'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "# Technical sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'TECH_BOWLING',\n",
    "    'Bowling',\n",
    "    'Fast bowling and spin bowling',\n",
    "    keywords=['bowling', 'fast', 'spin', 'art form'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'TECH_BATTING',\n",
    "    'Batting',\n",
    "    'Batting techniques and mental aspects',\n",
    "    keywords=['batting', 'mental', 'willow'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'TECH_STATS',\n",
    "    'Statistics and Analysis',\n",
    "    'Cricket statistics and records',\n",
    "    keywords=['statistics', 'records', 'depth'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'TECH_COACHING',\n",
    "    'Coaching and Training',\n",
    "    'Modern coaching and scientific approach',\n",
    "    keywords=['coaching', 'scientific', 'training'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "# Culture sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'CULT_COMMUNITY',\n",
    "    'Community',\n",
    "    'Community building and social connection',\n",
    "    keywords=['community', 'together', 'clubs', 'grassroots', 'childhood'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'CULT_RIVALRY',\n",
    "    'Rivalries',\n",
    "    'International rivalries and traditions',\n",
    "    keywords=['rivalry', 'india', 'pakistan', 'unmatched', 'ashes'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'CULT_EXPERIENCE',\n",
    "    'Fan Experience',\n",
    "    'Spectator experience and atmosphere',\n",
    "    keywords=['atmosphere', 'watching', 'ground', 'commentary', 'experience', 'sound'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'CULT_SPIRIT',\n",
    "    'Spirit of Cricket',\n",
    "    'Sportsmanship and game spirit',\n",
    "    keywords=['spirit', 'sledging', 'gamesmanship'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "# Development sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'DEV_WOMEN',\n",
    "    \"Women's Cricket\",\n",
    "    \"Growth of women's cricket\",\n",
    "    keywords=[\"women's\", 'womens', 'recognition', 'deserved'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_TECH',\n",
    "    'Technology',\n",
    "    'DRS and technological innovations',\n",
    "    keywords=['drs', 'technology', 'decision-making', 'accuracy'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_COMMERCIAL',\n",
    "    'Commercialization',\n",
    "    'Commercial aspects and business',\n",
    "    keywords=['commercialization', 'commercial', 'revolutionized'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_GLOBAL',\n",
    "    'Global Reach',\n",
    "    'Expanding cricket globally',\n",
    "    keywords=['olympics', 'global', 'reach', 'rise', 'bangladesh'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_INTEGRITY',\n",
    "    'Integrity Issues',\n",
    "    'Match-fixing and integrity',\n",
    "    keywords=['fixing', 'match-fixing', 'seriously'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(cricket_frame.codes)} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_cricket['codes'] = df_cricket['response'].apply(\n",
    "    lambda x: cricket_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_cricket[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "cricket_summary = cricket_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(cricket_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    cricket_summary[cricket_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Cricket Analysis Code Distribution',\n",
    "    color_continuous_scale='Greens'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Fashion Industry Analysis (Fashion Dataset)\n\n",
    "Analyze fashion trends, sustainability, and consumer attitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion dataset\n",
    "df_fashion = data_loader.load_csv('data/fashion_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_fashion)} responses\")\n",
    "print(f\"Data shape: {df_fashion.shape}\")\n",
    "display(df_fashion.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Define Fashion Industry Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for fashion analysis\n",
    "fashion_frame = CodeFrame(\n",
    "    name=\"Fashion Industry Analysis\",\n",
    "    description=\"Code frame for analyzing fashion trends and consumer attitudes\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "fashion_frame.add_code('SUSTAINABILITY', 'Sustainability', 'Environmental and ethical concerns')\n",
    "fashion_frame.add_code('CONSUMPTION', 'Consumption Patterns', 'Buying behavior and alternatives')\n",
    "fashion_frame.add_code('IDENTITY', 'Personal Identity', 'Self-expression and style')\n",
    "fashion_frame.add_code('INDUSTRY', 'Fashion Industry', 'Industry practices and trends')\n",
    "fashion_frame.add_code('SOCIAL', 'Social Issues', 'Inclusivity and representation')\n",
    "\n",
    "# Sustainability sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'SUS_ETHICAL',\n",
    "    'Ethical Fashion',\n",
    "    'Sustainable and ethical practices',\n",
    "    keywords=['sustainable', 'sustainability', 'ethical', 'ethics', 'essential', 'principles'],\n",
    "    parent='SUSTAINABILITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SUS_FAST',\n",
    "    'Fast Fashion Critique',\n",
    "    'Criticism of fast fashion',\n",
    "    keywords=['fast fashion', 'waste', 'environmental'],\n",
    "    parent='SUSTAINABILITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SUS_IMPACT',\n",
    "    'Environmental Impact',\n",
    "    'Carbon footprint and environmental concerns',\n",
    "    keywords=['carbon', 'footprint', 'alarming', 'environmental'],\n",
    "    parent='SUSTAINABILITY'\n",
    ")\n",
    "\n",
    "# Consumption sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'CON_QUALITY',\n",
    "    'Quality Focus',\n",
    "    'Quality over quantity approach',\n",
    "    keywords=['quality', 'quantity', 'guide', 'purchasing'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_VINTAGE',\n",
    "    'Vintage and Secondhand',\n",
    "    'Vintage clothing and resale',\n",
    "    keywords=['vintage', 'resale', 'market', 'reshaping'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_RENTAL',\n",
    "    'Alternative Models',\n",
    "    'Rental and sharing services',\n",
    "    keywords=['rental', 'services', 'alternatives'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_COST',\n",
    "    'Cost Barriers',\n",
    "    'Cost and accessibility issues',\n",
    "    keywords=['cost', 'prohibitive', 'expensive'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_MINIMALIST',\n",
    "    'Minimalism',\n",
    "    'Minimalist approach to wardrobes',\n",
    "    keywords=['minimalist', 'wardrobes', 'reduce', 'fatigue'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "# Identity sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'ID_PERSONAL',\n",
    "    'Personal Style',\n",
    "    'Individual expression and style',\n",
    "    keywords=['personal style', 'individuality', 'unique', 'expression', 'expresses'],\n",
    "    parent='IDENTITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'ID_CONFIDENCE',\n",
    "    'Self-Care and Wellbeing',\n",
    "    'Fashion as self-care and confidence',\n",
    "    keywords=['self-care', 'confidence', 'wellbeing', 'boosts'],\n",
    "    parent='IDENTITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'ID_COMFORT',\n",
    "    'Comfort Priority',\n",
    "    'Emphasis on comfort',\n",
    "    keywords=['comfort', 'aesthetics', 'prioritize'],\n",
    "    parent='IDENTITY'\n",
    ")\n",
    "\n",
    "# Industry sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'IND_LUXURY',\n",
    "    'Luxury Fashion',\n",
    "    'Luxury brands and haute couture',\n",
    "    keywords=['luxury', 'haute couture', 'craftsmanship', 'extraordinary'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_STREETWEAR',\n",
    "    'Streetwear',\n",
    "    'Streetwear and casual fashion',\n",
    "    keywords=['streetwear', 'mainstream'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_TRENDS',\n",
    "    'Trends and Shows',\n",
    "    'Fashion weeks and industry trends',\n",
    "    keywords=['fashion week', 'trends', 'set', 'industry'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_MEDIA',\n",
    "    'Media and Influence',\n",
    "    'Social media and influencers',\n",
    "    keywords=['social media', 'influencers', 'democratized', 'photography', 'replaced'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_INNOVATION',\n",
    "    'Innovation',\n",
    "    'Digital fashion and new technologies',\n",
    "    keywords=['digital', 'nft', 'future', 'interesting'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_CRAFT',\n",
    "    'Traditional Crafts',\n",
    "    'Tailoring and traditional skills',\n",
    "    keywords=['tailoring', 'dying', 'art', 'form', 'craftsmanship'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "# Social issues sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'SOC_INCLUSIVITY',\n",
    "    'Size Inclusivity',\n",
    "    'Size diversity and inclusivity',\n",
    "    keywords=['inclusivity', 'size', 'inclusive'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_BODY',\n",
    "    'Body Positivity',\n",
    "    'Body positivity movement',\n",
    "    keywords=['body positivity', 'changing', 'advertising'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_GENDER',\n",
    "    'Gender Neutral',\n",
    "    'Gender-neutral fashion',\n",
    "    keywords=['gender-neutral', 'breaking', 'boundaries'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_CULTURE',\n",
    "    'Cultural Issues',\n",
    "    'Cultural appropriation and representation',\n",
    "    keywords=['cultural', 'appropriation', 'addressing', 'local', 'designers'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_EDUCATION',\n",
    "    'Education',\n",
    "    'Fashion education and awareness',\n",
    "    keywords=['education', 'should include', 'history'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_WORKPLACE',\n",
    "    'Workplace Fashion',\n",
    "    'Dress codes and workplace norms',\n",
    "    keywords=['workplace', 'dress codes', 'relaxed'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(fashion_frame.codes)} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_fashion['codes'] = df_fashion['response'].apply(\n",
    "    lambda x: fashion_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_fashion[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "fashion_summary = fashion_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(fashion_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    fashion_summary[fashion_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Fashion Industry Code Distribution',\n",
    "    color_continuous_scale='Purples'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Comparative Analysis Across Datasets\n\n",
    "Compare coding patterns and themes across all five datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparative summary\n",
    "comparative_data = [\n",
    "    {'Dataset': 'Remote Work', 'Responses': len(df), 'Unique Codes': len(remote_work_frame.codes), \n",
    "     'Avg Codes/Response': df['codes'].apply(len).mean()},\n",
    "    {'Dataset': 'Political Leadership', 'Responses': len(df_trump), 'Unique Codes': len(trump_frame.codes),\n",
    "     'Avg Codes/Response': df_trump['codes'].apply(len).mean()},\n",
    "    {'Dataset': 'Justice System', 'Responses': len(df_epstein), 'Unique Codes': len(epstein_frame.codes),\n",
    "     'Avg Codes/Response': df_epstein['codes'].apply(len).mean()},\n",
    "    {'Dataset': 'Cricket', 'Responses': len(df_cricket), 'Unique Codes': len(cricket_frame.codes),\n",
    "     'Avg Codes/Response': df_cricket['codes'].apply(len).mean()},\n",
    "    {'Dataset': 'Fashion', 'Responses': len(df_fashion), 'Unique Codes': len(fashion_frame.codes),\n",
    "     'Avg Codes/Response': df_fashion['codes'].apply(len).mean()}\n",
    "]\n",
    "\n",
    "comparative_df = pd.DataFrame(comparative_data)\n",
    "\n",
    "print(\"\\n=== Comparative Analysis ===\")\n",
    "display(comparative_df)\n",
    "\n",
    "# Visualize comparison\n",
    "fig = px.bar(\n",
    "    comparative_df,\n",
    "    x='Dataset',\n",
    "    y='Unique Codes',\n",
    "    title='Code Frame Complexity Across Datasets',\n",
    "    color='Avg Codes/Response',\n",
    "    text='Unique Codes',\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "# Average codes per response comparison\n",
    "fig = px.bar(\n",
    "    comparative_df,\n",
    "    x='Dataset',\n",
    "    y='Avg Codes/Response',\n",
    "    title='Coding Density: Average Codes per Response',\n",
    "    color='Dataset',\n",
    "    text='Avg Codes/Response'\n",
    ")\n",
    "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "fig.update_layout(height=500, showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "### Customization Options:\n",
    "1. **Modify Code Frames**: Update the code definitions to match your research needs\n",
    "2. **Refine Themes**: Adjust theme definitions and associated codes\n",
    "3. **Add Categories**: Create additional hierarchical categories\n",
    "4. **Load Your Data**: Replace sample data with your actual responses\n",
    "\n",
    "### Advanced Analysis:\n",
    "- Intercoder reliability testing\n",
    "- Temporal analysis of themes\n",
    "- Demographic comparisons\n",
    "- Sentiment analysis integration\n",
    "- Machine learning-assisted coding\n",
    "\n",
    "### Quality Assurance:\n",
    "- Run `make test` to execute unit tests\n",
    "- Run `make lint` to check code quality\n",
    "- Review coding consistency across responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}