{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Ended Coding Analysis\n",
    "\n",
    "This notebook provides a comprehensive framework for analyzing open-ended qualitative data through:\n",
    "- **Code Frames**: Systematic coding structures for categorizing data\n",
    "- **Themes**: Identification and analysis of recurring patterns\n",
    "- **Categorization**: Multi-level classification and organization of qualitative data\n",
    "\n",
    "## Features\n",
    "- Data loading from flat files (CSV, Excel) and databases (SQLite, PostgreSQL)\n",
    "- Interactive visualizations\n",
    "- Robust error handling\n",
    "- Code quality checks via Makefile\n",
    "- Comprehensive testing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import logging\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database connections\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# NLP and text analysis\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Module\n",
    "\n",
    "Robust data loading from multiple sources with comprehensive error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Handles data loading from various sources with error handling.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def load_csv(self, filepath: str, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from CSV file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to CSV file\n",
    "            **kwargs: Additional arguments for pd.read_csv\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with loaded data\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If file doesn't exist\n",
    "            pd.errors.EmptyDataError: If file is empty\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(filepath):\n",
    "                raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "            \n",
    "            df = pd.read_csv(filepath, **kwargs)\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from {filepath}\")\n",
    "            return df\n",
    "        \n",
    "        except pd.errors.EmptyDataError:\n",
    "            self.logger.error(f\"Empty file: {filepath}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading CSV {filepath}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_excel(self, filepath: str, sheet_name: Union[str, int] = 0, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from Excel file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to Excel file\n",
    "            sheet_name: Sheet name or index\n",
    "            **kwargs: Additional arguments for pd.read_excel\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with loaded data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(filepath):\n",
    "                raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "            \n",
    "            df = pd.read_excel(filepath, sheet_name=sheet_name, **kwargs)\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from {filepath}\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading Excel {filepath}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_from_sqlite(self, db_path: str, query: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from SQLite database.\n",
    "        \n",
    "        Args:\n",
    "            db_path: Path to SQLite database file\n",
    "            query: SQL query to execute\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with query results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            conn.close()\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from SQLite database\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading from SQLite: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def load_from_postgres(self, connection_string: str, query: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from PostgreSQL database.\n",
    "        \n",
    "        Args:\n",
    "            connection_string: PostgreSQL connection string\n",
    "            query: SQL query to execute\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with query results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            engine = create_engine(connection_string)\n",
    "            df = pd.read_sql_query(query, engine)\n",
    "            engine.dispose()\n",
    "            self.logger.info(f\"Successfully loaded {len(df)} rows from PostgreSQL database\")\n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading from PostgreSQL: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader()\n",
    "print(\"✓ DataLoader initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sample Data\n",
    "\n",
    "Load your qualitative data from various sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load from CSV\n",
    "try:\n",
    "    # Replace with your actual data file\n",
    "    if os.path.exists('data/sample_responses.csv'):\n",
    "        df = data_loader.load_csv('data/sample_responses.csv')\n",
    "    else:\n",
    "        # Create sample data for demonstration\n",
    "        df = pd.DataFrame({\n",
    "            'id': range(1, 21),\n",
    "            'response': [\n",
    "                'I love the flexibility of remote work',\n",
    "                'Better work-life balance is crucial',\n",
    "                'Communication challenges with team members',\n",
    "                'Increased productivity at home',\n",
    "                'Missing social interactions with colleagues',\n",
    "                'Technology issues affect my work',\n",
    "                'More time for family and personal activities',\n",
    "                'Difficulty separating work and personal life',\n",
    "                'Cost savings from not commuting',\n",
    "                'Feeling isolated from the team',\n",
    "                'Flexible schedule allows better time management',\n",
    "                'Video call fatigue is real',\n",
    "                'Can focus better without office distractions',\n",
    "                'Miss casual conversations at the office',\n",
    "                'Home office setup improves comfort',\n",
    "                'Internet connectivity problems',\n",
    "                'Appreciate the autonomy',\n",
    "                'Harder to build relationships remotely',\n",
    "                'Reduced stress from commuting',\n",
    "                'Challenging to stay motivated alone'\n",
    "            ],\n",
    "            'respondent_id': [f'R{i:03d}' for i in range(1, 21)],\n",
    "            'timestamp': pd.date_range(start='2024-01-01', periods=20, freq='D')\n",
    "        })\n",
    "        logger.info(\"Using sample demonstration data\")\n",
    "    \n",
    "    print(f\"\\nLoaded {len(df)} responses\")\n",
    "    print(f\"\\nData shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    display(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code Frames\n",
    "\n",
    "Code frames provide a structured approach to categorizing qualitative data. Define your coding scheme here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeFrame:\n",
    "    \"\"\"Manages coding frames for qualitative analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, description: str = \"\"):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.codes = {}\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def add_code(self, code_id: str, label: str, description: str = \"\", \n",
    "                 keywords: Optional[List[str]] = None, parent: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Add a code to the frame.\n",
    "        \n",
    "        Args:\n",
    "            code_id: Unique identifier for the code\n",
    "            label: Human-readable label\n",
    "            description: Detailed description of the code\n",
    "            keywords: List of keywords associated with this code\n",
    "            parent: Parent code ID for hierarchical structures\n",
    "        \"\"\"\n",
    "        self.codes[code_id] = {\n",
    "            'label': label,\n",
    "            'description': description,\n",
    "            'keywords': keywords or [],\n",
    "            'parent': parent,\n",
    "            'count': 0\n",
    "        }\n",
    "        self.logger.info(f\"Added code: {code_id} - {label}\")\n",
    "    \n",
    "    def apply_codes(self, text: str, case_sensitive: bool = False) -> List[str]:\n",
    "        \"\"\"\n",
    "        Apply codes to text based on keyword matching.\n",
    "        \n",
    "        Args:\n",
    "            text: Text to code\n",
    "            case_sensitive: Whether to use case-sensitive matching\n",
    "            \n",
    "        Returns:\n",
    "            List of matching code IDs\n",
    "        \"\"\"\n",
    "        if not case_sensitive:\n",
    "            text = text.lower()\n",
    "        \n",
    "        matched_codes = []\n",
    "        for code_id, code_info in self.codes.items():\n",
    "            keywords = code_info['keywords']\n",
    "            if not case_sensitive:\n",
    "                keywords = [k.lower() for k in keywords]\n",
    "            \n",
    "            for keyword in keywords:\n",
    "                if keyword in text:\n",
    "                    matched_codes.append(code_id)\n",
    "                    self.codes[code_id]['count'] += 1\n",
    "                    break\n",
    "        \n",
    "        return matched_codes\n",
    "    \n",
    "    def get_hierarchy(self) -> Dict:\n",
    "        \"\"\"Get hierarchical structure of codes.\"\"\"\n",
    "        hierarchy = defaultdict(list)\n",
    "        for code_id, code_info in self.codes.items():\n",
    "            parent = code_info.get('parent')\n",
    "            if parent:\n",
    "                hierarchy[parent].append(code_id)\n",
    "            else:\n",
    "                hierarchy['root'].append(code_id)\n",
    "        return dict(hierarchy)\n",
    "    \n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate summary statistics of code usage.\"\"\"\n",
    "        summary_data = []\n",
    "        for code_id, code_info in self.codes.items():\n",
    "            summary_data.append({\n",
    "                'Code ID': code_id,\n",
    "                'Label': code_info['label'],\n",
    "                'Count': code_info['count'],\n",
    "                'Parent': code_info.get('parent', 'None')\n",
    "            })\n",
    "        return pd.DataFrame(summary_data).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"✓ CodeFrame class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define Your Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code frame for analyzing remote work experiences\n",
    "remote_work_frame = CodeFrame(\n",
    "    name=\"Remote Work Analysis\",\n",
    "    description=\"Coding frame for analyzing remote work experiences\"\n",
    ")\n",
    "\n",
    "# Define main categories (top-level codes)\n",
    "remote_work_frame.add_code(\n",
    "    'POSITIVE',\n",
    "    'Positive Experiences',\n",
    "    'Positive aspects of remote work'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEGATIVE',\n",
    "    'Negative Experiences',\n",
    "    'Challenges and negative aspects of remote work'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEUTRAL',\n",
    "    'Neutral/Mixed',\n",
    "    'Neutral or mixed experiences'\n",
    ")\n",
    "\n",
    "# Define sub-codes for positive experiences\n",
    "remote_work_frame.add_code(\n",
    "    'POS_FLEX',\n",
    "    'Flexibility',\n",
    "    'Flexibility in schedule and location',\n",
    "    keywords=['flexibility', 'flexible', 'autonomy', 'schedule'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_BALANCE',\n",
    "    'Work-Life Balance',\n",
    "    'Improved work-life balance',\n",
    "    keywords=['work-life balance', 'family', 'personal activities', 'time management'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_PROD',\n",
    "    'Productivity',\n",
    "    'Increased productivity',\n",
    "    keywords=['productivity', 'productive', 'focus', 'efficient'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_COST',\n",
    "    'Cost Savings',\n",
    "    'Financial benefits',\n",
    "    keywords=['cost savings', 'commuting', 'save money', 'reduced stress'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "# Define sub-codes for negative experiences\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_COMM',\n",
    "    'Communication Issues',\n",
    "    'Communication and collaboration challenges',\n",
    "    keywords=['communication', 'challenges', 'video call', 'fatigue'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_SOCIAL',\n",
    "    'Social Isolation',\n",
    "    'Lack of social interaction',\n",
    "    keywords=['isolated', 'social', 'miss', 'lonely', 'relationships'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_TECH',\n",
    "    'Technical Issues',\n",
    "    'Technology and infrastructure problems',\n",
    "    keywords=['technology', 'internet', 'connectivity', 'technical'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_BOUND',\n",
    "    'Work-Life Boundaries',\n",
    "    'Difficulty maintaining boundaries',\n",
    "    keywords=['separating', 'boundaries', 'motivated', 'personal life'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Code frame '{remote_work_frame.name}' created with {len(remote_work_frame.codes)} codes\")\n",
    "print(f\"\\nHierarchy: {remote_work_frame.get_hierarchy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Apply Codes to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes to each response\n",
    "df['codes'] = df['response'].apply(\n",
    "    lambda x: remote_work_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "# Create binary columns for each code\n",
    "for code_id in remote_work_frame.codes.keys():\n",
    "    df[f'code_{code_id}'] = df['codes'].apply(lambda x: 1 if code_id in x else 0)\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df[['response', 'codes']].head(10))\n",
    "\n",
    "# Show code summary\n",
    "print(\"\\nCode Summary:\")\n",
    "code_summary = remote_work_frame.summary()\n",
    "display(code_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visualize Code Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of code frequencies\n",
    "fig = px.bar(\n",
    "    code_summary,\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Code Distribution in Responses',\n",
    "    labels={'Label': 'Code', 'Count': 'Frequency'},\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Hierarchical sunburst chart\n",
    "sunburst_data = []\n",
    "for code_id, code_info in remote_work_frame.codes.items():\n",
    "    parent = code_info.get('parent', '')\n",
    "    sunburst_data.append({\n",
    "        'labels': code_info['label'],\n",
    "        'parents': remote_work_frame.codes[parent]['label'] if parent else '',\n",
    "        'values': code_info['count']\n",
    "    })\n",
    "\n",
    "sunburst_df = pd.DataFrame(sunburst_data)\n",
    "fig = px.sunburst(\n",
    "    sunburst_df,\n",
    "    names='labels',\n",
    "    parents='parents',\n",
    "    values='values',\n",
    "    title='Hierarchical Code Structure'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Themes\n",
    "\n",
    "Identify and analyze recurring themes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThemeAnalyzer:\n",
    "    \"\"\"Analyzes and identifies themes in qualitative data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.themes = {}\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def define_theme(self, theme_id: str, name: str, description: str, \n",
    "                    associated_codes: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Define a theme.\n",
    "        \n",
    "        Args:\n",
    "            theme_id: Unique identifier\n",
    "            name: Theme name\n",
    "            description: Detailed description\n",
    "            associated_codes: List of code IDs associated with this theme\n",
    "        \"\"\"\n",
    "        self.themes[theme_id] = {\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'codes': associated_codes or [],\n",
    "            'responses': []\n",
    "        }\n",
    "        self.logger.info(f\"Defined theme: {theme_id} - {name}\")\n",
    "    \n",
    "    def identify_themes(self, df: pd.DataFrame, code_column: str = 'codes') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Identify themes in coded data.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with coded responses\n",
    "            code_column: Column name containing codes\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with theme assignments\n",
    "        \"\"\"\n",
    "        theme_assignments = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            response_codes = set(row[code_column])\n",
    "            matched_themes = []\n",
    "            \n",
    "            for theme_id, theme_info in self.themes.items():\n",
    "                theme_codes = set(theme_info['codes'])\n",
    "                if response_codes & theme_codes:  # Intersection\n",
    "                    matched_themes.append(theme_id)\n",
    "                    self.themes[theme_id]['responses'].append(idx)\n",
    "            \n",
    "            theme_assignments.append(matched_themes)\n",
    "        \n",
    "        df['themes'] = theme_assignments\n",
    "        return df\n",
    "    \n",
    "    def theme_co_occurrence(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate co-occurrence matrix of themes.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with theme co-occurrence counts\n",
    "        \"\"\"\n",
    "        theme_ids = list(self.themes.keys())\n",
    "        n_themes = len(theme_ids)\n",
    "        co_occurrence = np.zeros((n_themes, n_themes))\n",
    "        \n",
    "        # Count co-occurrences\n",
    "        for theme_info in self.themes.values():\n",
    "            responses = theme_info['responses']\n",
    "            # This is simplified - you'd check actual response overlaps\n",
    "        \n",
    "        return pd.DataFrame(\n",
    "            co_occurrence,\n",
    "            index=[self.themes[t]['name'] for t in theme_ids],\n",
    "            columns=[self.themes[t]['name'] for t in theme_ids]\n",
    "        )\n",
    "    \n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate theme summary statistics.\"\"\"\n",
    "        summary_data = []\n",
    "        for theme_id, theme_info in self.themes.items():\n",
    "            summary_data.append({\n",
    "                'Theme ID': theme_id,\n",
    "                'Name': theme_info['name'],\n",
    "                'Description': theme_info['description'],\n",
    "                'Associated Codes': len(theme_info['codes']),\n",
    "                'Frequency': len(theme_info['responses'])\n",
    "            })\n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"✓ ThemeAnalyzer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Define Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize theme analyzer\n",
    "theme_analyzer = ThemeAnalyzer()\n",
    "\n",
    "# Define themes based on code patterns\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_AUTONOMY',\n",
    "    'Autonomy and Control',\n",
    "    'Themes related to personal autonomy, control over schedule, and independence',\n",
    "    associated_codes=['POS_FLEX', 'POS_BALANCE']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_PERFORMANCE',\n",
    "    'Work Performance',\n",
    "    'Themes related to productivity, efficiency, and work output',\n",
    "    associated_codes=['POS_PROD', 'NEG_TECH']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_CONNECTION',\n",
    "    'Social Connection',\n",
    "    'Themes related to social interaction, relationships, and collaboration',\n",
    "    associated_codes=['NEG_SOCIAL', 'NEG_COMM']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_WELLBEING',\n",
    "    'Personal Wellbeing',\n",
    "    'Themes related to mental health, stress, and life quality',\n",
    "    associated_codes=['POS_COST', 'POS_BALANCE', 'NEG_BOUND']\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Defined {len(theme_analyzer.themes)} themes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Identify Themes in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply theme identification\n",
    "df = theme_analyzer.identify_themes(df)\n",
    "\n",
    "print(\"\\nResponses with Identified Themes:\")\n",
    "display(df[['response', 'codes', 'themes']].head(10))\n",
    "\n",
    "# Show theme summary\n",
    "print(\"\\nTheme Summary:\")\n",
    "theme_summary = theme_analyzer.summary()\n",
    "display(theme_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme frequency bar chart\n",
    "fig = px.bar(\n",
    "    theme_summary,\n",
    "    x='Name',\n",
    "    y='Frequency',\n",
    "    title='Theme Distribution',\n",
    "    color='Frequency',\n",
    "    color_continuous_scale='Viridis',\n",
    "    hover_data=['Description']\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Theme network visualization\n",
    "# Count theme co-occurrences\n",
    "theme_counts = Counter()\n",
    "theme_pairs = Counter()\n",
    "\n",
    "for themes in df['themes']:\n",
    "    for theme in themes:\n",
    "        theme_counts[theme] += 1\n",
    "    \n",
    "    # Count pairs\n",
    "    for i, theme1 in enumerate(themes):\n",
    "        for theme2 in themes[i+1:]:\n",
    "            pair = tuple(sorted([theme1, theme2]))\n",
    "            theme_pairs[pair] += 1\n",
    "\n",
    "print(\"\\nTheme Co-occurrences:\")\n",
    "for pair, count in theme_pairs.most_common():\n",
    "    print(f\"{pair[0]} <-> {pair[1]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorization\n",
    "\n",
    "Advanced categorization and classification of coded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryManager:\n",
    "    \"\"\"Manages multi-level categorization of qualitative data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.categories = {}\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "    \n",
    "    def create_category(self, category_id: str, name: str, \n",
    "                       criteria: Dict, level: int = 1):\n",
    "        \"\"\"\n",
    "        Create a category.\n",
    "        \n",
    "        Args:\n",
    "            category_id: Unique identifier\n",
    "            name: Category name\n",
    "            criteria: Dictionary defining categorization criteria\n",
    "            level: Hierarchical level (1 = top level)\n",
    "        \"\"\"\n",
    "        self.categories[category_id] = {\n",
    "            'name': name,\n",
    "            'criteria': criteria,\n",
    "            'level': level,\n",
    "            'count': 0\n",
    "        }\n",
    "        self.logger.info(f\"Created category: {category_id} - {name} (Level {level})\")\n",
    "    \n",
    "    def categorize(self, df: pd.DataFrame, \n",
    "                   code_columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply categorization to DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to categorize\n",
    "            code_columns: List of code column names to consider\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with category assignments\n",
    "        \"\"\"\n",
    "        categories_assigned = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            assigned = []\n",
    "            \n",
    "            for cat_id, cat_info in self.categories.items():\n",
    "                if self._meets_criteria(row, cat_info['criteria']):\n",
    "                    assigned.append(cat_id)\n",
    "                    self.categories[cat_id]['count'] += 1\n",
    "            \n",
    "            categories_assigned.append(assigned)\n",
    "        \n",
    "        df['categories'] = categories_assigned\n",
    "        return df\n",
    "    \n",
    "    def _meets_criteria(self, row: pd.Series, criteria: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a row meets category criteria.\n",
    "        \n",
    "        Args:\n",
    "            row: DataFrame row\n",
    "            criteria: Criteria dictionary\n",
    "            \n",
    "        Returns:\n",
    "            True if criteria are met\n",
    "        \"\"\"\n",
    "        for key, value in criteria.items():\n",
    "            if key == 'codes_required':\n",
    "                # Check if any required codes are present\n",
    "                if not any(code in row.get('codes', []) for code in value):\n",
    "                    return False\n",
    "            \n",
    "            elif key == 'codes_all':\n",
    "                # Check if all codes are present\n",
    "                if not all(code in row.get('codes', []) for code in value):\n",
    "                    return False\n",
    "            \n",
    "            elif key == 'themes_required':\n",
    "                # Check if any required themes are present\n",
    "                if not any(theme in row.get('themes', []) for theme in value):\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate category summary.\"\"\"\n",
    "        summary_data = []\n",
    "        for cat_id, cat_info in self.categories.items():\n",
    "            summary_data.append({\n",
    "                'Category ID': cat_id,\n",
    "                'Name': cat_info['name'],\n",
    "                'Level': cat_info['level'],\n",
    "                'Count': cat_info['count']\n",
    "            })\n",
    "        return pd.DataFrame(summary_data).sort_values('Level')\n",
    "    \n",
    "    def cross_tabulation(self, df: pd.DataFrame, \n",
    "                        category1: str, category2: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create cross-tabulation between categories.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with categories\n",
    "            category1: First category ID\n",
    "            category2: Second category ID\n",
    "            \n",
    "        Returns:\n",
    "            Cross-tabulation DataFrame\n",
    "        \"\"\"\n",
    "        # Create binary indicators\n",
    "        df[f'has_{category1}'] = df['categories'].apply(\n",
    "            lambda x: 1 if category1 in x else 0\n",
    "        )\n",
    "        df[f'has_{category2}'] = df['categories'].apply(\n",
    "            lambda x: 1 if category2 in x else 0\n",
    "        )\n",
    "        \n",
    "        return pd.crosstab(\n",
    "            df[f'has_{category1}'],\n",
    "            df[f'has_{category2}'],\n",
    "            rownames=[self.categories[category1]['name']],\n",
    "            colnames=[self.categories[category2]['name']]\n",
    "        )\n",
    "\n",
    "print(\"✓ CategoryManager class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Define Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize category manager\n",
    "category_manager = CategoryManager()\n",
    "\n",
    "# Level 1: Primary sentiment\n",
    "category_manager.create_category(\n",
    "    'CAT_POSITIVE',\n",
    "    'Overall Positive',\n",
    "    {'codes_required': ['POS_FLEX', 'POS_BALANCE', 'POS_PROD', 'POS_COST']},\n",
    "    level=1\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_NEGATIVE',\n",
    "    'Overall Negative',\n",
    "    {'codes_required': ['NEG_COMM', 'NEG_SOCIAL', 'NEG_TECH', 'NEG_BOUND']},\n",
    "    level=1\n",
    ")\n",
    "\n",
    "# Level 2: Specific aspects\n",
    "category_manager.create_category(\n",
    "    'CAT_WORK_FOCUSED',\n",
    "    'Work-Focused',\n",
    "    {'codes_required': ['POS_PROD', 'NEG_TECH', 'NEG_COMM']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_LIFE_FOCUSED',\n",
    "    'Life-Focused',\n",
    "    {'codes_required': ['POS_BALANCE', 'POS_COST', 'NEG_BOUND']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_SOCIAL_FOCUSED',\n",
    "    'Social-Focused',\n",
    "    {'codes_required': ['NEG_SOCIAL', 'NEG_COMM']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Created {len(category_manager.categories)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Apply Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply categories to data\n",
    "df = category_manager.categorize(df)\n",
    "\n",
    "print(\"\\nCategorized Responses:\")\n",
    "display(df[['response', 'codes', 'themes', 'categories']].head(10))\n",
    "\n",
    "# Show category summary\n",
    "print(\"\\nCategory Summary:\")\n",
    "category_summary = category_manager.summary()\n",
    "display(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualize Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution by level\n",
    "fig = px.bar(\n",
    "    category_summary,\n",
    "    x='Name',\n",
    "    y='Count',\n",
    "    color='Level',\n",
    "    title='Category Distribution by Hierarchical Level',\n",
    "    barmode='group'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Pie chart of primary categories\n",
    "level1_cats = category_summary[category_summary['Level'] == 1]\n",
    "fig = px.pie(\n",
    "    level1_cats,\n",
    "    values='Count',\n",
    "    names='Name',\n",
    "    title='Primary Category Distribution'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Analysis & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisReporter:\n",
    "    \"\"\"Generates comprehensive analysis reports.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, code_frame: CodeFrame, \n",
    "                 theme_analyzer: ThemeAnalyzer, category_manager: CategoryManager):\n",
    "        self.df = df\n",
    "        self.code_frame = code_frame\n",
    "        self.theme_analyzer = theme_analyzer\n",
    "        self.category_manager = category_manager\n",
    "    \n",
    "    def generate_summary_stats(self) -> Dict:\n",
    "        \"\"\"Generate summary statistics.\"\"\"\n",
    "        stats = {\n",
    "            'total_responses': len(self.df),\n",
    "            'total_codes': len(self.code_frame.codes),\n",
    "            'total_themes': len(self.theme_analyzer.themes),\n",
    "            'total_categories': len(self.category_manager.categories),\n",
    "            'avg_codes_per_response': self.df['codes'].apply(len).mean(),\n",
    "            'avg_themes_per_response': self.df['themes'].apply(len).mean(),\n",
    "            'avg_categories_per_response': self.df['categories'].apply(len).mean()\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    def create_dashboard(self):\n",
    "        \"\"\"Create interactive dashboard.\"\"\"\n",
    "        from plotly.subplots import make_subplots\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'Code Distribution',\n",
    "                'Theme Distribution',\n",
    "                'Category Distribution',\n",
    "                'Coverage Statistics'\n",
    "            ),\n",
    "            specs=[\n",
    "                [{'type': 'bar'}, {'type': 'bar'}],\n",
    "                [{'type': 'bar'}, {'type': 'indicator'}]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Code distribution\n",
    "        code_summary = self.code_frame.summary()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=code_summary['Label'], y=code_summary['Count'], name='Codes'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Theme distribution\n",
    "        theme_summary = self.theme_analyzer.summary()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=theme_summary['Name'], y=theme_summary['Frequency'], name='Themes'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Category distribution\n",
    "        category_summary = self.category_manager.summary()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=category_summary['Name'], y=category_summary['Count'], name='Categories'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Coverage indicator\n",
    "        stats = self.generate_summary_stats()\n",
    "        fig.add_trace(\n",
    "            go.Indicator(\n",
    "                mode=\"number+delta\",\n",
    "                value=stats['avg_codes_per_response'],\n",
    "                title={\"text\": \"Avg Codes/Response\"},\n",
    "                delta={'reference': 1}\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=800, showlegend=False, title_text=\"Open-Ended Coding Analysis Dashboard\")\n",
    "        return fig\n",
    "\n",
    "# Create reporter\n",
    "reporter = AnalysisReporter(df, remote_work_frame, theme_analyzer, category_manager)\n",
    "\n",
    "# Generate summary statistics\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "stats = reporter.generate_summary_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value:.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "\n",
    "# Display dashboard\n",
    "print(\"\\n=== Analysis Dashboard ===\")\n",
    "dashboard = reporter.create_dashboard()\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export coded data\n",
    "output_file = output_dir / 'coded_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Exported coded data to {output_file}\")\n",
    "\n",
    "# Export code summary\n",
    "code_summary = remote_work_frame.summary()\n",
    "code_summary.to_csv(output_dir / 'code_summary.csv', index=False)\n",
    "print(f\"✓ Exported code summary to {output_dir / 'code_summary.csv'}\")\n",
    "\n",
    "# Export theme summary\n",
    "theme_summary = theme_analyzer.summary()\n",
    "theme_summary.to_csv(output_dir / 'theme_summary.csv', index=False)\n",
    "print(f\"✓ Exported theme summary to {output_dir / 'theme_summary.csv'}\")\n",
    "\n",
    "# Export category summary\n",
    "category_summary = category_manager.summary()\n",
    "category_summary.to_csv(output_dir / 'category_summary.csv', index=False)\n",
    "print(f\"✓ Exported category summary to {output_dir / 'category_summary.csv'}\")\n",
    "\n",
    "print(\"\\n✓ All results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "### Customization Options:\n",
    "1. **Modify Code Frames**: Update the code definitions to match your research needs\n",
    "2. **Refine Themes**: Adjust theme definitions and associated codes\n",
    "3. **Add Categories**: Create additional hierarchical categories\n",
    "4. **Load Your Data**: Replace sample data with your actual responses\n",
    "\n",
    "### Advanced Analysis:\n",
    "- Intercoder reliability testing\n",
    "- Temporal analysis of themes\n",
    "- Demographic comparisons\n",
    "- Sentiment analysis integration\n",
    "- Machine learning-assisted coding\n",
    "\n",
    "### Quality Assurance:\n",
    "- Run `make test` to execute unit tests\n",
    "- Run `make lint` to check code quality\n",
    "- Review coding consistency across responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
