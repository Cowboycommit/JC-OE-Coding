{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-Ended Coding Analysis\n",
    "\n",
    "This notebook provides a comprehensive framework for analyzing open-ended qualitative data through:\n",
    "- **Code Frames**: Systematic coding structures for categorizing data\n",
    "- **Themes**: Identification and analysis of recurring patterns\n",
    "- **Categorization**: Multi-level classification and organization of qualitative data\n",
    "\n",
    "## Features\n",
    "- Data loading from flat files (CSV, Excel) and databases (SQLite, PostgreSQL)\n",
    "- Interactive visualizations\n",
    "- Robust error handling\n",
    "- Code quality checks via Makefile\n",
    "- Comprehensive testing framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import logging\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database connections\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# NLP and text analysis\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "# Word cloud for text visualization\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "    print(\"Note: wordcloud not available. Install with: pip install wordcloud\")\n",
    "\n",
    "# Network analysis\n",
    "try:\n",
    "    import networkx as nx\n",
    "    NETWORKX_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NETWORKX_AVAILABLE = False\n",
    "    print(\"Note: networkx not available. Install with: pip install networkx\")\n",
    "\n",
    "# Add src to path and import modules\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "from src.data_loader import DataLoader\n",
    "from src.code_frame import CodeFrame\n",
    "from src.theme_analyzer import ThemeAnalyzer\n",
    "from src.category_manager import CategoryManager\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set Plotly default template\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "print(\"\u2713 All imports successful\")\n",
    "print(f\"\u2713 Imported from src: DataLoader, CodeFrame, ThemeAnalyzer, CategoryManager\")\n",
    "print(f\"\u2713 WordCloud available: {WORDCLOUD_AVAILABLE}\")\n",
    "print(f\"\u2713 NetworkX available: {NETWORKX_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Module\n",
    "\n",
    "Robust data loading from multiple sources with comprehensive error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization and Analysis Helper Functions\n",
    "\n",
    "Reusable functions for efficient analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_code_hierarchy_viz(code_frame: CodeFrame, title: str = \"Code Hierarchy\"):\n",
    "    \"\"\"\n",
    "    Create hierarchical sunburst visualization of code frame.\n",
    "    \n",
    "    Args:\n",
    "        code_frame: CodeFrame instance\n",
    "        title: Chart title\n",
    "    \"\"\"\n",
    "    sunburst_data = []\n",
    "    \n",
    "    # Add root\n",
    "    sunburst_data.append({\n",
    "        'labels': code_frame.name,\n",
    "        'parents': '',\n",
    "        'values': sum(info['count'] for info in code_frame.codes.values()),\n",
    "        'ids': 'root'\n",
    "    })\n",
    "    \n",
    "    # Add all codes\n",
    "    for code_id, code_info in code_frame.codes.items():\n",
    "        parent = code_info.get('parent', '')\n",
    "        if parent and parent in code_frame.codes:\n",
    "            parent_id = parent\n",
    "        else:\n",
    "            parent_id = 'root'\n",
    "        \n",
    "        sunburst_data.append({\n",
    "            'labels': code_info['label'],\n",
    "            'parents': parent_id,\n",
    "            'values': max(code_info['count'], 1),  # Use 1 if count is 0 for visibility\n",
    "            'ids': code_id\n",
    "        })\n",
    "    \n",
    "    df_sunburst = pd.DataFrame(sunburst_data)\n",
    "    \n",
    "    fig = px.sunburst(\n",
    "        df_sunburst,\n",
    "        names='labels',\n",
    "        parents='parents',\n",
    "        values='values',\n",
    "        title=title,\n",
    "        ids='ids'\n",
    "    )\n",
    "    fig.update_layout(height=600)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_code_heatmap(df: pd.DataFrame, code_frame: CodeFrame, title: str = \"Code Co-occurrence Heatmap\"):\n",
    "    \"\"\"\n",
    "    Create heatmap showing code co-occurrence patterns.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'codes' column\n",
    "        code_frame: CodeFrame instance\n",
    "        title: Chart title\n",
    "    \"\"\"\n",
    "    # Get active codes (those with count > 0)\n",
    "    active_codes = [code_id for code_id, info in code_frame.codes.items() if info['count'] > 0]\n",
    "    \n",
    "    if not active_codes:\n",
    "        print(\"No active codes to visualize\")\n",
    "        return None\n",
    "    \n",
    "    # Create co-occurrence matrix\n",
    "    n = len(active_codes)\n",
    "    cooccur = np.zeros((n, n))\n",
    "    \n",
    "    for codes_list in df['codes']:\n",
    "        for i, code1 in enumerate(active_codes):\n",
    "            for j, code2 in enumerate(active_codes):\n",
    "                if code1 in codes_list and code2 in codes_list:\n",
    "                    cooccur[i, j] += 1\n",
    "    \n",
    "    # Get labels\n",
    "    labels = [code_frame.codes[c]['label'] for c in active_codes]\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig = px.imshow(\n",
    "        cooccur,\n",
    "        labels=dict(x=\"Code\", y=\"Code\", color=\"Co-occurrences\"),\n",
    "        x=labels,\n",
    "        y=labels,\n",
    "        title=title,\n",
    "        color_continuous_scale='YlOrRd',\n",
    "        aspect='auto'\n",
    "    )\n",
    "    fig.update_layout(height=600)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_wordcloud_viz(df: pd.DataFrame, title: str = \"Response Word Cloud\"):\n",
    "    \"\"\"\n",
    "    Create word cloud from responses.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'response' column\n",
    "        title: Chart title\n",
    "    \"\"\"\n",
    "    if not WORDCLOUD_AVAILABLE:\n",
    "        print(\"WordCloud not available. Install with: pip install wordcloud\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all responses\n",
    "    text = ' '.join(df['response'].astype(str))\n",
    "    \n",
    "    # Create word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap='viridis',\n",
    "        max_words=100\n",
    "    ).generate(text)\n",
    "    \n",
    "    # Display using matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_network_graph(df: pd.DataFrame, code_frame: CodeFrame, title: str = \"Code Network\"):\n",
    "    \"\"\"\n",
    "    Create network graph showing code relationships.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'codes' column\n",
    "        code_frame: CodeFrame instance  \n",
    "        title: Chart title\n",
    "    \"\"\"\n",
    "    if not NETWORKX_AVAILABLE:\n",
    "        print(\"NetworkX not available. Install with: pip install networkx\")\n",
    "        return None\n",
    "    \n",
    "    # Build co-occurrence network\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for code_id, info in code_frame.codes.items():\n",
    "        if info['count'] > 0:\n",
    "            G.add_node(code_id, label=info['label'], count=info['count'])\n",
    "    \n",
    "    # Add edges based on co-occurrence\n",
    "    edge_weights = defaultdict(int)\n",
    "    for codes_list in df['codes']:\n",
    "        for i, code1 in enumerate(codes_list):\n",
    "            for code2 in codes_list[i+1:]:\n",
    "                edge = tuple(sorted([code1, code2]))\n",
    "                edge_weights[edge] += 1\n",
    "    \n",
    "    for (code1, code2), weight in edge_weights.items():\n",
    "        if code1 in G.nodes and code2 in G.nodes:\n",
    "            G.add_edge(code1, code2, weight=weight)\n",
    "    \n",
    "    if len(G.nodes) == 0:\n",
    "        print(\"No active codes to visualize\")\n",
    "        return None\n",
    "    \n",
    "    # Create layout\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "    \n",
    "    # Create edge trace\n",
    "    edge_trace = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        weight = G.edges[edge]['weight']\n",
    "        edge_trace.append(\n",
    "            go.Scatter(\n",
    "                x=[x0, x1, None],\n",
    "                y=[y0, y1, None],\n",
    "                mode='lines',\n",
    "                line=dict(width=weight*2, color='#888'),\n",
    "                hoverinfo='none',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Create node trace\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    node_size = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        label = G.nodes[node]['label']\n",
    "        count = G.nodes[node]['count']\n",
    "        node_text.append(f\"{label}<br>Count: {count}\")\n",
    "        node_size.append(10 + count * 3)\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers+text',\n",
    "        hovertext=node_text,\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            size=node_size,\n",
    "            color='lightblue',\n",
    "            line=dict(width=2, color='darkblue')\n",
    "        ),\n",
    "        text=[G.nodes[node]['label'][:10] for node in G.nodes()],\n",
    "        textposition='top center',\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=edge_trace + [node_trace])\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        height=600,\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_treemap(code_frame: CodeFrame, title: str = \"Code Distribution Treemap\"):\n",
    "    \"\"\"\n",
    "    Create treemap visualization of code distribution.\n",
    "    \n",
    "    Args:\n",
    "        code_frame: CodeFrame instance\n",
    "        title: Chart title\n",
    "    \"\"\"\n",
    "    treemap_data = []\n",
    "    \n",
    "    for code_id, code_info in code_frame.codes.items():\n",
    "        if code_info['count'] > 0:\n",
    "            parent = code_info.get('parent', '')\n",
    "            if not parent or parent not in code_frame.codes:\n",
    "                parent = code_frame.name\n",
    "            else:\n",
    "                parent = code_frame.codes[parent]['label']\n",
    "            \n",
    "            treemap_data.append({\n",
    "                'labels': code_info['label'],\n",
    "                'parents': parent,\n",
    "                'values': code_info['count']\n",
    "            })\n",
    "    \n",
    "    # Add root\n",
    "    treemap_data.append({\n",
    "        'labels': code_frame.name,\n",
    "        'parents': '',\n",
    "        'values': 0\n",
    "    })\n",
    "    \n",
    "    df_treemap = pd.DataFrame(treemap_data)\n",
    "    \n",
    "    fig = px.treemap(\n",
    "        df_treemap,\n",
    "        names='labels',\n",
    "        parents='parents',\n",
    "        values='values',\n",
    "        title=title\n",
    "    )\n",
    "    fig.update_layout(height=600)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def analyze_dataset(filepath: str, code_frame: CodeFrame, dataset_name: str, \n",
    "                   color_scheme: str = 'Blues'):\n",
    "    \"\"\"\n",
    "    Complete analysis pipeline for a dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to CSV file\n",
    "        code_frame: Configured CodeFrame instance\n",
    "        dataset_name: Name for display\n",
    "        color_scheme: Plotly color scheme\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with coded responses\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    loader = DataLoader()\n",
    "    df = loader.load_csv(filepath)\n",
    "    \n",
    "    # Apply codes\n",
    "    df['codes'] = df['response'].apply(\n",
    "        lambda x: code_frame.apply_codes(x, case_sensitive=False)\n",
    "    )\n",
    "    \n",
    "    # Display sample\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{dataset_name} Analysis\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Loaded {len(df)} responses\")\n",
    "    print(f\"\\nSample coded responses:\")\n",
    "    display(df[['response', 'codes']].head(5))\n",
    "    \n",
    "    # Code summary\n",
    "    summary = code_frame.summary()\n",
    "    active_summary = summary[summary['Count'] > 0]\n",
    "    \n",
    "    print(f\"\\nCode Summary (showing {len(active_summary)} active codes):\")\n",
    "    display(active_summary.head(10))\n",
    "    \n",
    "    # Visualizations\n",
    "    print(f\"\\nGenerating visualizations...\")\n",
    "    \n",
    "    # 1. Bar chart\n",
    "    fig = px.bar(\n",
    "        active_summary,\n",
    "        x='Label',\n",
    "        y='Count',\n",
    "        color='Count',\n",
    "        title=f'{dataset_name}: Code Distribution',\n",
    "        color_continuous_scale=color_scheme\n",
    "    )\n",
    "    fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "    fig.show()\n",
    "    \n",
    "    # 2. Hierarchical sunburst\n",
    "    fig = create_code_hierarchy_viz(code_frame, f\"{dataset_name}: Code Hierarchy\")\n",
    "    fig.show()\n",
    "    \n",
    "    # 3. Treemap\n",
    "    fig = create_treemap(code_frame, f\"{dataset_name}: Code Distribution Treemap\")\n",
    "    fig.show()\n",
    "    \n",
    "    # 4. Co-occurrence heatmap\n",
    "    fig = create_code_heatmap(df, code_frame, f\"{dataset_name}: Code Co-occurrence\")\n",
    "    if fig:\n",
    "        fig.show()\n",
    "    \n",
    "    # 5. Network graph\n",
    "    fig = create_network_graph(df, code_frame, f\"{dataset_name}: Code Network\")\n",
    "    if fig:\n",
    "        fig.show()\n",
    "    \n",
    "    # 6. Word cloud\n",
    "    fig = create_wordcloud_viz(df, f\"{dataset_name}: Word Cloud\")\n",
    "    if fig:\n",
    "        plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"\u2713 Helper functions defined\")\n",
    "print(\"  - create_code_hierarchy_viz()\")\n",
    "print(\"  - create_code_heatmap()\")\n",
    "print(\"  - create_wordcloud_viz()\")\n",
    "print(\"  - create_network_graph()\")\n",
    "print(\"  - create_treemap()\")\n",
    "print(\"  - analyze_dataset() [Complete analysis pipeline]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Data Loader\n",
    "\n",
    "Create data loader instance for loading from various sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = DataLoader()\n",
    "print(\"\u2713 DataLoader initialized\")\n",
    "print(\"\\nReady to load data from:\")\n",
    "print(\"  - CSV files\")\n",
    "print(\"  - Excel files\")\n",
    "print(\"  - SQLite databases\")\n",
    "print(\"  - PostgreSQL databases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Remote Work Analysis\n\nCode frames provide a structured approach to categorizing qualitative data. Define your coding scheme here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load Data and Define Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code frame for analyzing remote work experiences\n",
    "remote_work_frame = CodeFrame(\n",
    "    name=\"Remote Work Analysis\",\n",
    "    description=\"Coding frame for analyzing remote work experiences\"\n",
    ")\n",
    "\n",
    "# Define main categories (top-level codes)\n",
    "remote_work_frame.add_code(\n",
    "    'POSITIVE',\n",
    "    'Positive Experiences',\n",
    "    'Positive aspects of remote work'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEGATIVE',\n",
    "    'Negative Experiences',\n",
    "    'Challenges and negative aspects of remote work'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEUTRAL',\n",
    "    'Neutral/Mixed',\n",
    "    'Neutral or mixed experiences'\n",
    ")\n",
    "\n",
    "# Define sub-codes for positive experiences\n",
    "remote_work_frame.add_code(\n",
    "    'POS_FLEX',\n",
    "    'Flexibility',\n",
    "    'Flexibility in schedule and location',\n",
    "    keywords=['flexibility', 'flexible', 'autonomy', 'schedule'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_BALANCE',\n",
    "    'Work-Life Balance',\n",
    "    'Improved work-life balance',\n",
    "    keywords=['work-life balance', 'family', 'personal activities', 'time management'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_PROD',\n",
    "    'Productivity',\n",
    "    'Increased productivity',\n",
    "    keywords=['productivity', 'productive', 'focus', 'efficient'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'POS_COST',\n",
    "    'Cost Savings',\n",
    "    'Financial benefits',\n",
    "    keywords=['cost savings', 'commuting', 'save money', 'reduced stress'],\n",
    "    parent='POSITIVE'\n",
    ")\n",
    "\n",
    "# Define sub-codes for negative experiences\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_COMM',\n",
    "    'Communication Issues',\n",
    "    'Communication and collaboration challenges',\n",
    "    keywords=['communication', 'challenges', 'video call', 'fatigue'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_SOCIAL',\n",
    "    'Social Isolation',\n",
    "    'Lack of social interaction',\n",
    "    keywords=['isolated', 'social', 'miss', 'lonely', 'relationships'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_TECH',\n",
    "    'Technical Issues',\n",
    "    'Technology and infrastructure problems',\n",
    "    keywords=['technology', 'internet', 'connectivity', 'technical'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "remote_work_frame.add_code(\n",
    "    'NEG_BOUND',\n",
    "    'Work-Life Boundaries',\n",
    "    'Difficulty maintaining boundaries',\n",
    "    keywords=['separating', 'boundaries', 'motivated', 'personal life'],\n",
    "    parent='NEGATIVE'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame '{remote_work_frame.name}' created with {len(remote_work_frame.codes)} codes\")\n",
    "print(f\"\\nHierarchy: {remote_work_frame.get_hierarchy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Apply Codes and Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes to each response\n",
    "df['codes'] = df['response'].apply(\n",
    "    lambda x: remote_work_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "# Create binary columns for each code\n",
    "for code_id in remote_work_frame.codes.keys():\n",
    "    df[f'code_{code_id}'] = df['codes'].apply(lambda x: 1 if code_id in x else 0)\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df[['response', 'codes']].head(10))\n",
    "\n",
    "# Show code summary\n",
    "print(\"\\nCode Summary:\")\n",
    "code_summary = remote_work_frame.summary()\n",
    "display(code_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of code frequencies\n",
    "fig = px.bar(\n",
    "    code_summary,\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Code Distribution in Responses',\n",
    "    labels={'Label': 'Code', 'Count': 'Frequency'},\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Hierarchical sunburst chart\n",
    "sunburst_data = []\n",
    "for code_id, code_info in remote_work_frame.codes.items():\n",
    "    parent = code_info.get('parent', '')\n",
    "    sunburst_data.append({\n",
    "        'labels': code_info['label'],\n",
    "        'parents': remote_work_frame.codes[parent]['label'] if parent else '',\n",
    "        'values': code_info['count']\n",
    "    })\n",
    "\n",
    "sunburst_df = pd.DataFrame(sunburst_data)\n",
    "fig = px.sunburst(\n",
    "    sunburst_df,\n",
    "    names='labels',\n",
    "    parents='parents',\n",
    "    values='values',\n",
    "    title='Hierarchical Code Structure'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Themes\n",
    "\n",
    "Identify and analyze recurring themes in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Define Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize theme analyzer\n",
    "theme_analyzer = ThemeAnalyzer()\n",
    "\n",
    "# Define themes based on code patterns\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_AUTONOMY',\n",
    "    'Autonomy and Control',\n",
    "    'Themes related to personal autonomy, control over schedule, and independence',\n",
    "    associated_codes=['POS_FLEX', 'POS_BALANCE']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_PERFORMANCE',\n",
    "    'Work Performance',\n",
    "    'Themes related to productivity, efficiency, and work output',\n",
    "    associated_codes=['POS_PROD', 'NEG_TECH']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_CONNECTION',\n",
    "    'Social Connection',\n",
    "    'Themes related to social interaction, relationships, and collaboration',\n",
    "    associated_codes=['NEG_SOCIAL', 'NEG_COMM']\n",
    ")\n",
    "\n",
    "theme_analyzer.define_theme(\n",
    "    'THEME_WELLBEING',\n",
    "    'Personal Wellbeing',\n",
    "    'Themes related to mental health, stress, and life quality',\n",
    "    associated_codes=['POS_COST', 'POS_BALANCE', 'NEG_BOUND']\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Defined {len(theme_analyzer.themes)} themes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Identify Themes in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply theme identification\n",
    "df = theme_analyzer.identify_themes(df)\n",
    "\n",
    "print(\"\\nResponses with Identified Themes:\")\n",
    "display(df[['response', 'codes', 'themes']].head(10))\n",
    "\n",
    "# Show theme summary\n",
    "print(\"\\nTheme Summary:\")\n",
    "theme_summary = theme_analyzer.summary()\n",
    "display(theme_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theme frequency bar chart\n",
    "fig = px.bar(\n",
    "    theme_summary,\n",
    "    x='Name',\n",
    "    y='Frequency',\n",
    "    title='Theme Distribution',\n",
    "    color='Frequency',\n",
    "    color_continuous_scale='Viridis',\n",
    "    hover_data=['Description']\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Theme network visualization\n",
    "# Count theme co-occurrences\n",
    "theme_counts = Counter()\n",
    "theme_pairs = Counter()\n",
    "\n",
    "for themes in df['themes']:\n",
    "    for theme in themes:\n",
    "        theme_counts[theme] += 1\n",
    "    \n",
    "    # Count pairs\n",
    "    for i, theme1 in enumerate(themes):\n",
    "        for theme2 in themes[i+1:]:\n",
    "            pair = tuple(sorted([theme1, theme2]))\n",
    "            theme_pairs[pair] += 1\n",
    "\n",
    "print(\"\\nTheme Co-occurrences:\")\n",
    "for pair, count in theme_pairs.most_common():\n",
    "    print(f\"{pair[0]} <-> {pair[1]}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorization\n",
    "\n",
    "Advanced categorization and classification of coded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Define Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize category manager\n",
    "category_manager = CategoryManager()\n",
    "\n",
    "# Level 1: Primary sentiment\n",
    "category_manager.create_category(\n",
    "    'CAT_POSITIVE',\n",
    "    'Overall Positive',\n",
    "    {'codes_required': ['POS_FLEX', 'POS_BALANCE', 'POS_PROD', 'POS_COST']},\n",
    "    level=1\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_NEGATIVE',\n",
    "    'Overall Negative',\n",
    "    {'codes_required': ['NEG_COMM', 'NEG_SOCIAL', 'NEG_TECH', 'NEG_BOUND']},\n",
    "    level=1\n",
    ")\n",
    "\n",
    "# Level 2: Specific aspects\n",
    "category_manager.create_category(\n",
    "    'CAT_WORK_FOCUSED',\n",
    "    'Work-Focused',\n",
    "    {'codes_required': ['POS_PROD', 'NEG_TECH', 'NEG_COMM']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_LIFE_FOCUSED',\n",
    "    'Life-Focused',\n",
    "    {'codes_required': ['POS_BALANCE', 'POS_COST', 'NEG_BOUND']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "category_manager.create_category(\n",
    "    'CAT_SOCIAL_FOCUSED',\n",
    "    'Social-Focused',\n",
    "    {'codes_required': ['NEG_SOCIAL', 'NEG_COMM']},\n",
    "    level=2\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Created {len(category_manager.categories)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Apply Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply categories to data\n",
    "df = category_manager.categorize(df)\n",
    "\n",
    "print(\"\\nCategorized Responses:\")\n",
    "display(df[['response', 'codes', 'themes', 'categories']].head(10))\n",
    "\n",
    "# Show category summary\n",
    "print(\"\\nCategory Summary:\")\n",
    "category_summary = category_manager.summary()\n",
    "display(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualize Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution by level\n",
    "fig = px.bar(\n",
    "    category_summary,\n",
    "    x='Name',\n",
    "    y='Count',\n",
    "    color='Level',\n",
    "    title='Category Distribution by Hierarchical Level',\n",
    "    barmode='group'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()\n",
    "\n",
    "# Pie chart of primary categories\n",
    "level1_cats = category_summary[category_summary['Level'] == 1]\n",
    "fig = px.pie(\n",
    "    level1_cats,\n",
    "    values='Count',\n",
    "    names='Name',\n",
    "    title='Primary Category Distribution'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Analysis & Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export coded data\n",
    "output_file = output_dir / 'coded_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\u2713 Exported coded data to {output_file}\")\n",
    "\n",
    "# Export code summary\n",
    "code_summary = remote_work_frame.summary()\n",
    "code_summary.to_csv(output_dir / 'code_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported code summary to {output_dir / 'code_summary.csv'}\")\n",
    "\n",
    "# Export theme summary\n",
    "theme_summary = theme_analyzer.summary()\n",
    "theme_summary.to_csv(output_dir / 'theme_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported theme summary to {output_dir / 'theme_summary.csv'}\")\n",
    "\n",
    "# Export category summary\n",
    "category_summary = category_manager.summary()\n",
    "category_summary.to_csv(output_dir / 'category_summary.csv', index=False)\n",
    "print(f\"\u2713 Exported category summary to {output_dir / 'category_summary.csv'}\")\n",
    "\n",
    "print(\"\\n\u2713 All results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# PART 2: Additional Dataset Analyses\n\nThe following sections demonstrate the framework with four additional datasets covering different research domains.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Political Leadership Analysis (Trump Dataset)\n\n",
    "Analyze political discourse, policy impacts, and public opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trump dataset\n",
    "df_trump = data_loader.load_csv('data/trump_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_trump)} responses\")\n",
    "print(f\"Data shape: {df_trump.shape}\")\n",
    "print(f\"Columns: {df_trump.columns.tolist()}\")\n",
    "display(df_trump.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Define Political Discourse Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for political discourse analysis\n",
    "trump_frame = CodeFrame(\n",
    "    name=\"Political Leadership Analysis\",\n",
    "    description=\"Code frame for analyzing political discourse and policy impacts\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "trump_frame.add_code('POLICY', 'Policy Analysis', 'Discussion of policies and their impacts')\n",
    "trump_frame.add_code('COMMUNICATION', 'Communication Style', 'Communication and rhetoric')\n",
    "trump_frame.add_code('GOVERNANCE', 'Governance', 'Leadership and governance approach')\n",
    "trump_frame.add_code('IMPACT', 'Political Impact', 'Political and social impacts')\n",
    "\n",
    "# Policy sub-codes\n",
    "trump_frame.add_code(\n",
    "    'POL_ECONOMY',\n",
    "    'Economic Policy',\n",
    "    'Trade, taxation, and economic impacts',\n",
    "    keywords=['trade', 'economy', 'economic', 'tax', 'taxation', 'business', 'corporate'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'POL_FOREIGN',\n",
    "    'Foreign Policy',\n",
    "    'International relations and foreign policy',\n",
    "    keywords=['foreign', 'international', 'nato', 'russia', 'china', 'diplomatic', 'agreements'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'POL_DOMESTIC',\n",
    "    'Domestic Policy',\n",
    "    'Immigration, healthcare, and domestic issues',\n",
    "    keywords=['immigration', 'healthcare', 'border', 'wall', 'domestic', 'reform'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'POL_JUDICIARY',\n",
    "    'Judicial Appointments',\n",
    "    'Court appointments and judicial impact',\n",
    "    keywords=['court', 'supreme', 'judicial', 'judges', 'appointments', 'nominees'],\n",
    "    parent='POLICY'\n",
    ")\n",
    "\n",
    "# Communication sub-codes\n",
    "trump_frame.add_code(\n",
    "    'COMM_MEDIA',\n",
    "    'Media Relations',\n",
    "    'Relationship with media and press coverage',\n",
    "    keywords=['media', 'press', 'coverage', 'fake news', 'adversarial'],\n",
    "    parent='COMMUNICATION'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'COMM_SOCIAL',\n",
    "    'Social Media',\n",
    "    'Twitter and social media usage',\n",
    "    keywords=['twitter', 'social media', 'tweets', 'unprecedented'],\n",
    "    parent='COMMUNICATION'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'COMM_RHETORIC',\n",
    "    'Political Rhetoric',\n",
    "    'Speaking style and political rhetoric',\n",
    "    keywords=['rhetoric', 'communication', 'style', 'unconventional', 'theatrical'],\n",
    "    parent='COMMUNICATION'\n",
    ")\n",
    "\n",
    "# Governance sub-codes\n",
    "trump_frame.add_code(\n",
    "    'GOV_LEADERSHIP',\n",
    "    'Leadership Style',\n",
    "    'Management and leadership approach',\n",
    "    keywords=['leadership', 'governance', 'management', 'approach', 'business'],\n",
    "    parent='GOVERNANCE'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'GOV_LOYALTY',\n",
    "    'Loyalty Dynamics',\n",
    "    'Loyalty expectations and demands',\n",
    "    keywords=['loyalty', 'demands', 'officials', 'unusual'],\n",
    "    parent='GOVERNANCE'\n",
    ")\n",
    "\n",
    "# Impact sub-codes\n",
    "trump_frame.add_code(\n",
    "    'IMP_VOTERS',\n",
    "    'Voter Impact',\n",
    "    'Impact on voter demographics and base',\n",
    "    keywords=['voters', 'base', 'demographics', 'energized', 'working-class', 'consistent'],\n",
    "    parent='IMPACT'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'IMP_POLITICAL',\n",
    "    'Political System Impact',\n",
    "    'Impact on political system and norms',\n",
    "    keywords=['impeachment', 'divisive', 'proceedings', 'political', 'pardons'],\n",
    "    parent='IMPACT'\n",
    ")\n",
    "\n",
    "trump_frame.add_code(\n",
    "    'IMP_LASTING',\n",
    "    'Long-term Impact',\n",
    "    'Lasting effects and legacy',\n",
    "    keywords=['lasting', 'impact', 'legacy', 'long-term', 'shift'],\n",
    "    parent='IMPACT'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(trump_frame.codes)} codes\")\n",
    "print(f\"Hierarchy: {trump_frame.get_hierarchy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_trump['codes'] = df_trump['response'].apply(\n",
    "    lambda x: trump_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_trump[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "trump_summary = trump_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(trump_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    trump_summary[trump_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Political Discourse Code Distribution',\n",
    "    color_continuous_scale='Reds'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Justice System Analysis (Epstein Dataset)\n\n",
    "Analyze institutional accountability and justice system issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Epstein dataset\n",
    "df_epstein = data_loader.load_csv('data/epstein_case_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_epstein)} responses\")\n",
    "print(f\"Data shape: {df_epstein.shape}\")\n",
    "display(df_epstein.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Define Justice System Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for justice system analysis\n",
    "epstein_frame = CodeFrame(\n",
    "    name=\"Justice System Analysis\",\n",
    "    description=\"Code frame for institutional accountability and justice system issues\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "epstein_frame.add_code('INSTITUTIONAL', 'Institutional Issues', 'Institutional failures and oversight')\n",
    "epstein_frame.add_code('LEGAL', 'Legal Process', 'Legal proceedings and justice system')\n",
    "epstein_frame.add_code('SOCIAL', 'Social Impact', 'Social and cultural implications')\n",
    "epstein_frame.add_code('REFORM', 'Reform Needs', 'Calls for reform and change')\n",
    "\n",
    "# Institutional sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'INST_OVERSIGHT',\n",
    "    'Oversight Failures',\n",
    "    'Failures in institutional oversight',\n",
    "    keywords=['oversight', 'failures', 'institutional', 'monitoring', 'procedures'],\n",
    "    parent='INSTITUTIONAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'INST_ACCOUNTABILITY',\n",
    "    'Accountability Issues',\n",
    "    'Questions of accountability and responsibility',\n",
    "    keywords=['accountability', 'responsible', 'connections', 'powerful', 'enablers'],\n",
    "    parent='INSTITUTIONAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'INST_PRIVILEGE',\n",
    "    'Privilege and Power',\n",
    "    'Role of wealth and privilege',\n",
    "    keywords=['privilege', 'wealth', 'power', 'preferential', 'treatment', 'factor'],\n",
    "    parent='INSTITUTIONAL'\n",
    ")\n",
    "\n",
    "# Legal process sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'LEG_JUSTICE',\n",
    "    'Justice System',\n",
    "    'Justice system handling and equal treatment',\n",
    "    keywords=['justice', 'equal', 'treatment', 'handling', 'system'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'LEG_PROCESS',\n",
    "    'Legal Process',\n",
    "    'Plea deals and prosecutorial decisions',\n",
    "    keywords=['plea', 'deal', 'prosecution', 'legal', 'decisions', 'prior'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'LEG_CUSTODY',\n",
    "    'Custody Issues',\n",
    "    'Death in custody and prison procedures',\n",
    "    keywords=['custody', 'death', 'prison', 'jail', 'procedures'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'LEG_INVESTIGATION',\n",
    "    'Investigations',\n",
    "    'Federal investigations and inquiries',\n",
    "    keywords=['investigation', 'federal', 'revealed', 'inquiries', 'pressure'],\n",
    "    parent='LEGAL'\n",
    ")\n",
    "\n",
    "# Social impact sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'SOC_VICTIMS',\n",
    "    'Victim Advocacy',\n",
    "    'Focus on victims and survivors',\n",
    "    keywords=['victims', 'survivors', 'believing', 'advocates', 'impact', 'support', 'compensation'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'SOC_TRUST',\n",
    "    'Public Trust',\n",
    "    'Impact on public trust in institutions',\n",
    "    keywords=['trust', 'public', 'damaged', 'confidence'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'SOC_AWARENESS',\n",
    "    'Social Awareness',\n",
    "    'Raising awareness about systemic issues',\n",
    "    keywords=['trafficking', 'problem', 'societal', 'awareness', 'attention'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'SOC_MEDIA',\n",
    "    'Media Role',\n",
    "    'Role of journalism and media coverage',\n",
    "    keywords=['media', 'journalism', 'coverage', 'reporting', 'sensitive'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "# Reform sub-codes\n",
    "epstein_frame.add_code(\n",
    "    'REF_LEGAL',\n",
    "    'Legal Reforms',\n",
    "    'Proposed legal and justice reforms',\n",
    "    keywords=['reform', 'proposed', 'prevent', 'criminal justice', 'transparency'],\n",
    "    parent='REFORM'\n",
    ")\n",
    "\n",
    "epstein_frame.add_code(\n",
    "    'REF_PROTECTION',\n",
    "    'Protection Systems',\n",
    "    'Need for better protection of vulnerable individuals',\n",
    "    keywords=['protection', 'vulnerable', 'inadequate', 'background', 'checks'],\n",
    "    parent='REFORM'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(epstein_frame.codes)} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_epstein['codes'] = df_epstein['response'].apply(\n",
    "    lambda x: epstein_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_epstein[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "epstein_summary = epstein_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(epstein_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    epstein_summary[epstein_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Justice System Code Distribution',\n",
    "    color_continuous_scale='Oranges'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cricket Analysis (Sports Dataset)\n\n",
    "Analyze cricket perspectives, formats, and cultural impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cricket dataset\n",
    "df_cricket = data_loader.load_csv('data/cricket_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_cricket)} responses\")\n",
    "print(f\"Data shape: {df_cricket.shape}\")\n",
    "display(df_cricket.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Define Cricket Analysis Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for cricket analysis\n",
    "cricket_frame = CodeFrame(\n",
    "    name=\"Cricket Analysis\",\n",
    "    description=\"Code frame for analyzing cricket perspectives and culture\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "cricket_frame.add_code('FORMATS', 'Cricket Formats', 'Different formats and competitions')\n",
    "cricket_frame.add_code('TECHNICAL', 'Technical Aspects', 'Skills, strategies, and techniques')\n",
    "cricket_frame.add_code('CULTURE', 'Cricket Culture', 'Cultural and social aspects')\n",
    "cricket_frame.add_code('DEVELOPMENT', 'Game Development', 'Evolution and modernization')\n",
    "\n",
    "# Format sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'FMT_TEST',\n",
    "    'Test Cricket',\n",
    "    'Test matches and traditional format',\n",
    "    keywords=['test', 'purest', 'ashes', 'resilience', 'strategy'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'FMT_T20',\n",
    "    'T20 Format',\n",
    "    'T20 cricket and innovations',\n",
    "    keywords=['t20', 'ipl', 'big bash', 'accessible', 'entertainment', 'innovations'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'FMT_LEAGUES',\n",
    "    'Leagues and Competitions',\n",
    "    'IPL, county championship, and leagues',\n",
    "    keywords=['league', 'ipl', 'county', 'championship', 'big bash', 'hundred'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'FMT_TOURNAMENTS',\n",
    "    'Major Tournaments',\n",
    "    'World Cup and major tournaments',\n",
    "    keywords=['world cup', 'tournament', 'pinnacle'],\n",
    "    parent='FORMATS'\n",
    ")\n",
    "\n",
    "# Technical sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'TECH_BOWLING',\n",
    "    'Bowling',\n",
    "    'Fast bowling and spin bowling',\n",
    "    keywords=['bowling', 'fast', 'spin', 'art form'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'TECH_BATTING',\n",
    "    'Batting',\n",
    "    'Batting techniques and mental aspects',\n",
    "    keywords=['batting', 'mental', 'willow'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'TECH_STATS',\n",
    "    'Statistics and Analysis',\n",
    "    'Cricket statistics and records',\n",
    "    keywords=['statistics', 'records', 'depth'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'TECH_COACHING',\n",
    "    'Coaching and Training',\n",
    "    'Modern coaching and scientific approach',\n",
    "    keywords=['coaching', 'scientific', 'training'],\n",
    "    parent='TECHNICAL'\n",
    ")\n",
    "\n",
    "# Culture sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'CULT_COMMUNITY',\n",
    "    'Community',\n",
    "    'Community building and social connection',\n",
    "    keywords=['community', 'together', 'clubs', 'grassroots', 'childhood'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'CULT_RIVALRY',\n",
    "    'Rivalries',\n",
    "    'International rivalries and traditions',\n",
    "    keywords=['rivalry', 'india', 'pakistan', 'unmatched', 'ashes'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'CULT_EXPERIENCE',\n",
    "    'Fan Experience',\n",
    "    'Spectator experience and atmosphere',\n",
    "    keywords=['atmosphere', 'watching', 'ground', 'commentary', 'experience', 'sound'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'CULT_SPIRIT',\n",
    "    'Spirit of Cricket',\n",
    "    'Sportsmanship and game spirit',\n",
    "    keywords=['spirit', 'sledging', 'gamesmanship'],\n",
    "    parent='CULTURE'\n",
    ")\n",
    "\n",
    "# Development sub-codes\n",
    "cricket_frame.add_code(\n",
    "    'DEV_WOMEN',\n",
    "    \"Women's Cricket\",\n",
    "    \"Growth of women's cricket\",\n",
    "    keywords=[\"women's\", 'womens', 'recognition', 'deserved'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_TECH',\n",
    "    'Technology',\n",
    "    'DRS and technological innovations',\n",
    "    keywords=['drs', 'technology', 'decision-making', 'accuracy'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_COMMERCIAL',\n",
    "    'Commercialization',\n",
    "    'Commercial aspects and business',\n",
    "    keywords=['commercialization', 'commercial', 'revolutionized'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_GLOBAL',\n",
    "    'Global Reach',\n",
    "    'Expanding cricket globally',\n",
    "    keywords=['olympics', 'global', 'reach', 'rise', 'bangladesh'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "cricket_frame.add_code(\n",
    "    'DEV_INTEGRITY',\n",
    "    'Integrity Issues',\n",
    "    'Match-fixing and integrity',\n",
    "    keywords=['fixing', 'match-fixing', 'seriously'],\n",
    "    parent='DEVELOPMENT'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(cricket_frame.codes)} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_cricket['codes'] = df_cricket['response'].apply(\n",
    "    lambda x: cricket_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_cricket[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "cricket_summary = cricket_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(cricket_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    cricket_summary[cricket_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Cricket Analysis Code Distribution',\n",
    "    color_continuous_scale='Greens'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Fashion Industry Analysis (Fashion Dataset)\n\n",
    "Analyze fashion trends, sustainability, and consumer attitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion dataset\n",
    "df_fashion = data_loader.load_csv('data/fashion_responses.csv')\n",
    "\n",
    "print(f\"\\nLoaded {len(df_fashion)} responses\")\n",
    "print(f\"Data shape: {df_fashion.shape}\")\n",
    "display(df_fashion.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Define Fashion Industry Code Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create code frame for fashion analysis\n",
    "fashion_frame = CodeFrame(\n",
    "    name=\"Fashion Industry Analysis\",\n",
    "    description=\"Code frame for analyzing fashion trends and consumer attitudes\"\n",
    ")\n",
    "\n",
    "# Main categories\n",
    "fashion_frame.add_code('SUSTAINABILITY', 'Sustainability', 'Environmental and ethical concerns')\n",
    "fashion_frame.add_code('CONSUMPTION', 'Consumption Patterns', 'Buying behavior and alternatives')\n",
    "fashion_frame.add_code('IDENTITY', 'Personal Identity', 'Self-expression and style')\n",
    "fashion_frame.add_code('INDUSTRY', 'Fashion Industry', 'Industry practices and trends')\n",
    "fashion_frame.add_code('SOCIAL', 'Social Issues', 'Inclusivity and representation')\n",
    "\n",
    "# Sustainability sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'SUS_ETHICAL',\n",
    "    'Ethical Fashion',\n",
    "    'Sustainable and ethical practices',\n",
    "    keywords=['sustainable', 'sustainability', 'ethical', 'ethics', 'essential', 'principles'],\n",
    "    parent='SUSTAINABILITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SUS_FAST',\n",
    "    'Fast Fashion Critique',\n",
    "    'Criticism of fast fashion',\n",
    "    keywords=['fast fashion', 'waste', 'environmental'],\n",
    "    parent='SUSTAINABILITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SUS_IMPACT',\n",
    "    'Environmental Impact',\n",
    "    'Carbon footprint and environmental concerns',\n",
    "    keywords=['carbon', 'footprint', 'alarming', 'environmental'],\n",
    "    parent='SUSTAINABILITY'\n",
    ")\n",
    "\n",
    "# Consumption sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'CON_QUALITY',\n",
    "    'Quality Focus',\n",
    "    'Quality over quantity approach',\n",
    "    keywords=['quality', 'quantity', 'guide', 'purchasing'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_VINTAGE',\n",
    "    'Vintage and Secondhand',\n",
    "    'Vintage clothing and resale',\n",
    "    keywords=['vintage', 'resale', 'market', 'reshaping'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_RENTAL',\n",
    "    'Alternative Models',\n",
    "    'Rental and sharing services',\n",
    "    keywords=['rental', 'services', 'alternatives'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_COST',\n",
    "    'Cost Barriers',\n",
    "    'Cost and accessibility issues',\n",
    "    keywords=['cost', 'prohibitive', 'expensive'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'CON_MINIMALIST',\n",
    "    'Minimalism',\n",
    "    'Minimalist approach to wardrobes',\n",
    "    keywords=['minimalist', 'wardrobes', 'reduce', 'fatigue'],\n",
    "    parent='CONSUMPTION'\n",
    ")\n",
    "\n",
    "# Identity sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'ID_PERSONAL',\n",
    "    'Personal Style',\n",
    "    'Individual expression and style',\n",
    "    keywords=['personal style', 'individuality', 'unique', 'expression', 'expresses'],\n",
    "    parent='IDENTITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'ID_CONFIDENCE',\n",
    "    'Self-Care and Wellbeing',\n",
    "    'Fashion as self-care and confidence',\n",
    "    keywords=['self-care', 'confidence', 'wellbeing', 'boosts'],\n",
    "    parent='IDENTITY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'ID_COMFORT',\n",
    "    'Comfort Priority',\n",
    "    'Emphasis on comfort',\n",
    "    keywords=['comfort', 'aesthetics', 'prioritize'],\n",
    "    parent='IDENTITY'\n",
    ")\n",
    "\n",
    "# Industry sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'IND_LUXURY',\n",
    "    'Luxury Fashion',\n",
    "    'Luxury brands and haute couture',\n",
    "    keywords=['luxury', 'haute couture', 'craftsmanship', 'extraordinary'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_STREETWEAR',\n",
    "    'Streetwear',\n",
    "    'Streetwear and casual fashion',\n",
    "    keywords=['streetwear', 'mainstream'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_TRENDS',\n",
    "    'Trends and Shows',\n",
    "    'Fashion weeks and industry trends',\n",
    "    keywords=['fashion week', 'trends', 'set', 'industry'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_MEDIA',\n",
    "    'Media and Influence',\n",
    "    'Social media and influencers',\n",
    "    keywords=['social media', 'influencers', 'democratized', 'photography', 'replaced'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_INNOVATION',\n",
    "    'Innovation',\n",
    "    'Digital fashion and new technologies',\n",
    "    keywords=['digital', 'nft', 'future', 'interesting'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'IND_CRAFT',\n",
    "    'Traditional Crafts',\n",
    "    'Tailoring and traditional skills',\n",
    "    keywords=['tailoring', 'dying', 'art', 'form', 'craftsmanship'],\n",
    "    parent='INDUSTRY'\n",
    ")\n",
    "\n",
    "# Social issues sub-codes\n",
    "fashion_frame.add_code(\n",
    "    'SOC_INCLUSIVITY',\n",
    "    'Size Inclusivity',\n",
    "    'Size diversity and inclusivity',\n",
    "    keywords=['inclusivity', 'size', 'inclusive'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_BODY',\n",
    "    'Body Positivity',\n",
    "    'Body positivity movement',\n",
    "    keywords=['body positivity', 'changing', 'advertising'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_GENDER',\n",
    "    'Gender Neutral',\n",
    "    'Gender-neutral fashion',\n",
    "    keywords=['gender-neutral', 'breaking', 'boundaries'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_CULTURE',\n",
    "    'Cultural Issues',\n",
    "    'Cultural appropriation and representation',\n",
    "    keywords=['cultural', 'appropriation', 'addressing', 'local', 'designers'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_EDUCATION',\n",
    "    'Education',\n",
    "    'Fashion education and awareness',\n",
    "    keywords=['education', 'should include', 'history'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "fashion_frame.add_code(\n",
    "    'SOC_WORKPLACE',\n",
    "    'Workplace Fashion',\n",
    "    'Dress codes and workplace norms',\n",
    "    keywords=['workplace', 'dress codes', 'relaxed'],\n",
    "    parent='SOCIAL'\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Code frame created with {len(fashion_frame.codes)} codes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Apply Codes and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply codes\n",
    "df_fashion['codes'] = df_fashion['response'].apply(\n",
    "    lambda x: fashion_frame.apply_codes(x, case_sensitive=False)\n",
    ")\n",
    "\n",
    "print(\"\\nCoded Responses:\")\n",
    "display(df_fashion[['response', 'topic', 'codes']].head(10))\n",
    "\n",
    "# Code summary\n",
    "fashion_summary = fashion_frame.summary()\n",
    "print(\"\\nCode Summary:\")\n",
    "display(fashion_summary)\n",
    "\n",
    "# Visualize\n",
    "fig = px.bar(\n",
    "    fashion_summary[fashion_summary['Count'] > 0],\n",
    "    x='Label',\n",
    "    y='Count',\n",
    "    color='Count',\n",
    "    title='Fashion Industry Code Distribution',\n",
    "    color_continuous_scale='Purples'\n",
    ")\n",
    "fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Enhanced Comparative Analysis\n",
    "\n",
    "Advanced cross-dataset comparison with sophisticated visualizations and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all datasets and code frames\n",
    "datasets_info = [\n",
    "    {'name': 'Remote Work', 'df': df, 'frame': remote_work_frame, 'color': 'Blues'},\n",
    "    {'name': 'Political Leadership', 'df': df_trump, 'frame': trump_frame, 'color': 'Reds'},\n",
    "    {'name': 'Justice System', 'df': df_epstein, 'frame': epstein_frame, 'color': 'Oranges'},\n",
    "    {'name': 'Cricket', 'df': df_cricket, 'frame': cricket_frame, 'color': 'Greens'},\n",
    "    {'name': 'Fashion', 'df': df_fashion, 'frame': fashion_frame, 'color': 'Purples'}\n",
    "]\n",
    "\n",
    "# Create comprehensive comparative metrics\n",
    "comparative_data = []\n",
    "\n",
    "for info in datasets_info:\n",
    "    dataset_df = info['df']\n",
    "    frame = info['frame']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_codes = len(frame.codes)\n",
    "    active_codes = sum(1 for c in frame.codes.values() if c['count'] > 0)\n",
    "    total_responses = len(dataset_df)\n",
    "    avg_codes = dataset_df['codes'].apply(len).mean()\n",
    "    max_codes = dataset_df['codes'].apply(len).max()\n",
    "    min_codes = dataset_df['codes'].apply(len).min()\n",
    "    std_codes = dataset_df['codes'].apply(len).std()\n",
    "    \n",
    "    # Coverage: % of responses with at least one code\n",
    "    coverage = (dataset_df['codes'].apply(len) > 0).sum() / len(dataset_df) * 100\n",
    "    \n",
    "    # Code utilization: % of codes that are actually used\n",
    "    utilization = (active_codes / total_codes * 100) if total_codes > 0 else 0\n",
    "    \n",
    "    comparative_data.append({\n",
    "        'Dataset': info['name'],\n",
    "        'Responses': total_responses,\n",
    "        'Total Codes': total_codes,\n",
    "        'Active Codes': active_codes,\n",
    "        'Avg Codes/Response': avg_codes,\n",
    "        'Max Codes/Response': max_codes,\n",
    "        'Min Codes/Response': min_codes,\n",
    "        'Std Dev': std_codes,\n",
    "        'Coverage %': coverage,\n",
    "        'Code Utilization %': utilization\n",
    "    })\n",
    "\n",
    "comp_df = pd.DataFrame(comparative_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE COMPARATIVE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "display(comp_df)\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAverage responses per dataset: {comp_df['Responses'].mean():.1f}\")\n",
    "print(f\"Average code frame size: {comp_df['Total Codes'].mean():.1f} codes\")\n",
    "print(f\"Average code utilization: {comp_df['Code Utilization %'].mean():.1f}%\")\n",
    "print(f\"Average coverage: {comp_df['Coverage %'].mean():.1f}%\")\n",
    "print(f\"\\nMost complex code frame: {comp_df.loc[comp_df['Total Codes'].idxmax(), 'Dataset']} ({comp_df['Total Codes'].max()} codes)\")\n",
    "print(f\"Highest coding density: {comp_df.loc[comp_df['Avg Codes/Response'].idxmax(), 'Dataset']} ({comp_df['Avg Codes/Response'].max():.2f} codes/response)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Code Frame Complexity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for multiple metrics\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Code Frame Size',\n",
    "        'Coding Density',\n",
    "        'Code Utilization Rate',\n",
    "        'Coverage Rate'\n",
    "    ),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
    "           [{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Color mapping\n",
    "colors = ['#3498db', '#e74c3c', '#f39c12', '#2ecc71', '#9b59b6']\n",
    "\n",
    "# Plot 1: Code Frame Size\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=comp_df['Dataset'],\n",
    "        y=comp_df['Total Codes'],\n",
    "        name='Total Codes',\n",
    "        marker_color=colors,\n",
    "        text=comp_df['Total Codes'],\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Coding Density\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=comp_df['Dataset'],\n",
    "        y=comp_df['Avg Codes/Response'],\n",
    "        name='Avg Codes/Response',\n",
    "        marker_color=colors,\n",
    "        text=comp_df['Avg Codes/Response'].round(2),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Code Utilization\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=comp_df['Dataset'],\n",
    "        y=comp_df['Code Utilization %'],\n",
    "        name='Utilization %',\n",
    "        marker_color=colors,\n",
    "        text=comp_df['Code Utilization %'].round(1),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Coverage\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=comp_df['Dataset'],\n",
    "        y=comp_df['Coverage %'],\n",
    "        name='Coverage %',\n",
    "        marker_color=colors,\n",
    "        text=comp_df['Coverage %'].round(1),\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    "    title_text=\"Comprehensive Code Frame Metrics Comparison\"\n",
    ")\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 Multi-Dimensional Radar Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize metrics to 0-100 scale for radar chart\n",
    "radar_data = comp_df.copy()\n",
    "\n",
    "# Normalize each metric\n",
    "for col in ['Total Codes', 'Active Codes', 'Avg Codes/Response']:\n",
    "    max_val = radar_data[col].max()\n",
    "    if max_val > 0:\n",
    "        radar_data[f'{col}_norm'] = (radar_data[col] / max_val * 100)\n",
    "\n",
    "# Create radar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "categories = ['Code Frame\\nSize', 'Active Codes', 'Coding\\nDensity', \n",
    "              'Utilization\\nRate', 'Coverage\\nRate']\n",
    "\n",
    "for idx, row in radar_data.iterrows():\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=[\n",
    "            row['Total Codes_norm'],\n",
    "            row['Active Codes_norm'],\n",
    "            row['Avg Codes/Response_norm'],\n",
    "            row['Code Utilization %'],\n",
    "            row['Coverage %']\n",
    "        ],\n",
    "        theta=categories,\n",
    "        fill='toself',\n",
    "        name=row['Dataset']\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 100]\n",
    "        )),\n",
    "    showlegend=True,\n",
    "    title=\"Multi-Dimensional Dataset Comparison (Normalized to 100)\",\n",
    "    height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3 Coding Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for coding distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, info in enumerate(datasets_info):\n",
    "    codes_per_response = info['df']['codes'].apply(len)\n",
    "    fig.add_trace(go.Box(\n",
    "        y=codes_per_response,\n",
    "        name=info['name'],\n",
    "        marker_color=colors[i],\n",
    "        boxmean='sd'  # Show mean and standard deviation\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of Codes per Response Across Datasets\",\n",
    "    yaxis_title=\"Number of Codes per Response\",\n",
    "    xaxis_title=\"Dataset\",\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Violin plot for more detailed distribution\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, info in enumerate(datasets_info):\n",
    "    codes_per_response = info['df']['codes'].apply(len)\n",
    "    fig.add_trace(go.Violin(\n",
    "        y=codes_per_response,\n",
    "        name=info['name'],\n",
    "        marker_color=colors[i],\n",
    "        box_visible=True,\n",
    "        meanline_visible=True\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Detailed Distribution Analysis (Violin Plot)\",\n",
    "    yaxis_title=\"Number of Codes per Response\",\n",
    "    xaxis_title=\"Dataset\",\n",
    "    height=500,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4 Metric Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix for metrics\n",
    "correlation_cols = ['Total Codes', 'Active Codes', 'Avg Codes/Response', \n",
    "                   'Coverage %', 'Code Utilization %']\n",
    "corr_matrix = comp_df[correlation_cols].corr()\n",
    "\n",
    "# Create annotated heatmap\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    labels=dict(color=\"Correlation\"),\n",
    "    x=correlation_cols,\n",
    "    y=correlation_cols,\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    zmin=-1, zmax=1,\n",
    "    title=\"Correlation Between Coding Metrics\",\n",
    "    aspect='auto'\n",
    ")\n",
    "\n",
    "# Add correlation values as text\n",
    "fig.update_traces(\n",
    "    text=corr_matrix.round(2).values,\n",
    "    texttemplate='%{text}'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nKey Correlations:\")\n",
    "print(\"=\"*60)\n",
    "for i in range(len(correlation_cols)):\n",
    "    for j in range(i+1, len(correlation_cols)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.5:\n",
    "            direction = \"positive\" if corr_val > 0 else \"negative\"\n",
    "            print(f\"{correlation_cols[i]} <-> {correlation_cols[j]}: {corr_val:.2f} ({direction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5 Parallel Coordinates Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parallel coordinates plot\n",
    "fig = px.parallel_coordinates(\n",
    "    comp_df,\n",
    "    dimensions=['Total Codes', 'Active Codes', 'Avg Codes/Response', \n",
    "               'Coverage %', 'Code Utilization %'],\n",
    "    color='Avg Codes/Response',\n",
    "    labels={\"Total Codes\": \"Total Codes\",\n",
    "           \"Active Codes\": \"Active Codes\",\n",
    "           \"Avg Codes/Response\": \"Avg Codes/Response\",\n",
    "           \"Coverage %\": \"Coverage %\",\n",
    "           \"Code Utilization %\": \"Utilization %\"},\n",
    "    color_continuous_scale='Viridis',\n",
    "    title=\"Parallel Coordinates: Multi-Metric Comparison\"\n",
    ")\n",
    "\n",
    "# Add dataset labels\n",
    "for i, row in comp_df.iterrows():\n",
    "    fig.add_annotation(\n",
    "        x=-0.05,\n",
    "        y=i/len(comp_df),\n",
    "        text=row['Dataset'],\n",
    "        showarrow=False,\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        xanchor='right'\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "### Customization Options:\n",
    "1. **Modify Code Frames**: Update the code definitions to match your research needs\n",
    "2. **Refine Themes**: Adjust theme definitions and associated codes\n",
    "3. **Add Categories**: Create additional hierarchical categories\n",
    "4. **Load Your Data**: Replace sample data with your actual responses\n",
    "\n",
    "### Advanced Analysis:\n",
    "- Intercoder reliability testing\n",
    "- Temporal analysis of themes\n",
    "- Demographic comparisons\n",
    "- Sentiment analysis integration\n",
    "- Machine learning-assisted coding\n",
    "\n",
    "### Quality Assurance:\n",
    "- Run `make test` to execute unit tests\n",
    "- Run `make lint` to check code quality\n",
    "- Review coding consistency across responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}