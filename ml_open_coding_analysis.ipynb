{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Based Open Coding Analysis\n",
    "\n",
    "This notebook provides a **comprehensive ML-powered framework** for analyzing open-ended qualitative data with:\n",
    "\n",
    "## 15 Essential Outputs:\n",
    "1. **Code Assignments** - Which codes apply to each response with confidence scores\n",
    "2. **Code Frame/Codebook** - Complete list of codes with definitions and examples\n",
    "3. **Code Frequency Table** - Statistical distribution of code usage\n",
    "4. **Confidence/Quality Metrics** - Model reliability and performance metrics\n",
    "5. **Binary/Multi-Label Matrix** - Code presence/absence for statistical analysis\n",
    "6. **Representative Quotes** - Top examples for each code\n",
    "7. **Co-Occurrence Analysis** - Code relationship patterns\n",
    "8. **Descriptive Statistics** - Comprehensive summary statistics\n",
    "9. **Segmentation/Subgroup Analysis** - Code patterns across demographics\n",
    "10. **Quality Assurance Report** - Validation and error analysis\n",
    "11. **Visualizations** - Interactive charts and network diagrams\n",
    "12. **Exportable Datasets** - Multiple format exports (CSV, Excel, JSON)\n",
    "13. **Model/Method Documentation** - Transparent methodology\n",
    "14. **Uncoded/Ambiguous Responses** - Edge cases and low-confidence items\n",
    "15. **Executive Summary** - High-level insights for stakeholders\n",
    "\n",
    "## Features:\n",
    "- \ud83e\udd16 Multiple ML algorithms (TF-IDF, embeddings, clustering)\n",
    "- \ud83d\udcca Advanced visualizations (networks, heatmaps, interactive plots)\n",
    "- \ud83d\udcc8 Statistical analysis and quality metrics\n",
    "- \ud83d\udcbe Multiple export formats\n",
    "- \ud83d\udd0d Automatic theme discovery\n",
    "- \u2705 Quality assurance and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "except:\n",
    "    print(\"Note: Some NLTK downloads may have failed. Continuing...\")\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Word clouds\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "    print(\"Note: wordcloud not available. Install with: pip install wordcloud\")\n",
    "\n",
    "# Network analysis\n",
    "try:\n",
    "    import networkx as nx\n",
    "    NETWORKX_AVAILABLE = True\n",
    "except ImportError:\n",
    "    NETWORKX_AVAILABLE = False\n",
    "    print(\"Note: networkx not available. Install with: pip install networkx\")\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\u2713 All imports successful\")\n",
    "print(f\"\u2713 WordCloud available: {WORDCLOUD_AVAILABLE}\")\n",
    "print(f\"\u2713 NetworkX available: {NETWORKX_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML-Based Coding Engine\n",
    "\n",
    "Core engine for automatic code discovery and assignment using machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLOpenCoder:\n",
    "    \"\"\"\n",
    "    ML-powered open coding system with automatic theme discovery.\n",
    "    \n",
    "    Features:\n",
    "    - Automatic code discovery using topic modeling\n",
    "    - Confidence scores for all assignments\n",
    "    - Multiple algorithm support\n",
    "    - Quality metrics and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_codes=10, method='tfidf_kmeans', min_confidence=0.3):\n",
    "        \"\"\"\n",
    "        Initialize ML Open Coder.\n",
    "        \n",
    "        Args:\n",
    "            n_codes: Number of codes/themes to discover\n",
    "            method: Algorithm to use ('tfidf_kmeans', 'lda', 'nmf')\n",
    "            min_confidence: Minimum confidence threshold for code assignment\n",
    "        \"\"\"\n",
    "        self.n_codes = n_codes\n",
    "        self.method = method\n",
    "        self.min_confidence = min_confidence\n",
    "        \n",
    "        self.vectorizer = None\n",
    "        self.model = None\n",
    "        self.codebook = {}\n",
    "        self.code_assignments = None\n",
    "        self.confidence_scores = None\n",
    "        self.feature_matrix = None\n",
    "        \n",
    "        # Initialize lemmatizer\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text.\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters but keep spaces\n",
    "        text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def fit(self, responses, stop_words='english'):\n",
    "        \"\"\"\n",
    "        Discover codes from responses using ML.\n",
    "        \n",
    "        Args:\n",
    "            responses: List or Series of response texts\n",
    "            stop_words: Stop words to remove\n",
    "        \"\"\"\n",
    "        # Preprocess\n",
    "        processed = [self.preprocess_text(r) for r in responses]\n",
    "        \n",
    "        # Vectorize\n",
    "        if self.method == 'lda':\n",
    "            self.vectorizer = CountVectorizer(\n",
    "                max_features=1000,\n",
    "                stop_words=stop_words,\n",
    "                min_df=2,\n",
    "                max_df=0.8\n",
    "            )\n",
    "            self.feature_matrix = self.vectorizer.fit_transform(processed)\n",
    "            self.model = LatentDirichletAllocation(\n",
    "                n_components=self.n_codes,\n",
    "                random_state=42,\n",
    "                max_iter=20\n",
    "            )\n",
    "        \n",
    "        elif self.method == 'nmf':\n",
    "            self.vectorizer = TfidfVectorizer(\n",
    "                max_features=1000,\n",
    "                stop_words=stop_words,\n",
    "                min_df=2,\n",
    "                max_df=0.8\n",
    "            )\n",
    "            self.feature_matrix = self.vectorizer.fit_transform(processed)\n",
    "            self.model = NMF(\n",
    "                n_components=self.n_codes,\n",
    "                random_state=42,\n",
    "                max_iter=200\n",
    "            )\n",
    "        \n",
    "        else:  # tfidf_kmeans (default)\n",
    "            self.vectorizer = TfidfVectorizer(\n",
    "                max_features=1000,\n",
    "                stop_words=stop_words,\n",
    "                min_df=2,\n",
    "                max_df=0.8,\n",
    "                ngram_range=(1, 2)\n",
    "            )\n",
    "            self.feature_matrix = self.vectorizer.fit_transform(processed)\n",
    "            self.model = KMeans(\n",
    "                n_clusters=self.n_codes,\n",
    "                random_state=42,\n",
    "                n_init=10\n",
    "            )\n",
    "        \n",
    "        # Fit model\n",
    "        logger.info(f\"Fitting {self.method} model with {self.n_codes} codes...\")\n",
    "        \n",
    "        if self.method in ['lda', 'nmf']:\n",
    "            doc_topic_matrix = self.model.fit_transform(self.feature_matrix)\n",
    "        else:\n",
    "            labels = self.model.fit_predict(self.feature_matrix)\n",
    "            # Convert to topic distribution\n",
    "            doc_topic_matrix = np.zeros((len(responses), self.n_codes))\n",
    "            for i, label in enumerate(labels):\n",
    "                doc_topic_matrix[i, label] = 1.0\n",
    "        \n",
    "        # Generate codebook\n",
    "        self._generate_codebook()\n",
    "        \n",
    "        # Assign codes with confidence\n",
    "        self._assign_codes(doc_topic_matrix, responses)\n",
    "        \n",
    "        logger.info(f\"\u2713 Model fitted successfully\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _generate_codebook(self, top_words=10):\n",
    "        \"\"\"Generate codebook from model.\"\"\"\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        for code_idx in range(self.n_codes):\n",
    "            code_id = f\"CODE_{code_idx + 1:02d}\"\n",
    "            \n",
    "            # Get top words for this code\n",
    "            if self.method in ['lda', 'nmf']:\n",
    "                topic_weights = self.model.components_[code_idx]\n",
    "                top_indices = topic_weights.argsort()[-top_words:][::-1]\n",
    "            else:  # kmeans\n",
    "                cluster_center = self.model.cluster_centers_[code_idx]\n",
    "                top_indices = cluster_center.argsort()[-top_words:][::-1]\n",
    "            \n",
    "            top_words_list = [feature_names[i] for i in top_indices]\n",
    "            \n",
    "            # Generate label from top words\n",
    "            label = ' '.join(top_words_list[:3]).title()\n",
    "            \n",
    "            self.codebook[code_id] = {\n",
    "                'label': label,\n",
    "                'keywords': top_words_list,\n",
    "                'count': 0,\n",
    "                'examples': [],\n",
    "                'avg_confidence': 0.0\n",
    "            }\n",
    "    \n",
    "    def _assign_codes(self, doc_topic_matrix, responses):\n",
    "        \"\"\"Assign codes to documents with confidence scores.\"\"\"\n",
    "        assignments = []\n",
    "        confidences = []\n",
    "        \n",
    "        for doc_idx, topic_dist in enumerate(doc_topic_matrix):\n",
    "            # Get codes above confidence threshold\n",
    "            doc_codes = []\n",
    "            doc_confidences = []\n",
    "            \n",
    "            for code_idx, confidence in enumerate(topic_dist):\n",
    "                if confidence >= self.min_confidence:\n",
    "                    code_id = f\"CODE_{code_idx + 1:02d}\"\n",
    "                    doc_codes.append(code_id)\n",
    "                    doc_confidences.append(float(confidence))\n",
    "                    \n",
    "                    # Update codebook stats\n",
    "                    self.codebook[code_id]['count'] += 1\n",
    "                    \n",
    "                    # Store example if confidence is high\n",
    "                    if confidence > 0.6 and len(self.codebook[code_id]['examples']) < 10:\n",
    "                        self.codebook[code_id]['examples'].append({\n",
    "                            'text': str(responses[doc_idx]),\n",
    "                            'confidence': float(confidence)\n",
    "                        })\n",
    "            \n",
    "            assignments.append(doc_codes)\n",
    "            confidences.append(doc_confidences)\n",
    "        \n",
    "        # Calculate average confidence per code\n",
    "        for doc_codes, doc_confs in zip(assignments, confidences):\n",
    "            for code, conf in zip(doc_codes, doc_confs):\n",
    "                if self.codebook[code]['count'] > 0:\n",
    "                    current_avg = self.codebook[code]['avg_confidence']\n",
    "                    count = self.codebook[code]['count']\n",
    "                    self.codebook[code]['avg_confidence'] = (\n",
    "                        (current_avg * (count - 1) + conf) / count\n",
    "                    )\n",
    "        \n",
    "        self.code_assignments = assignments\n",
    "        self.confidence_scores = confidences\n",
    "    \n",
    "    def get_codebook_df(self):\n",
    "        \"\"\"Return codebook as DataFrame.\"\"\"\n",
    "        data = []\n",
    "        for code_id, info in self.codebook.items():\n",
    "            data.append({\n",
    "                'Code ID': code_id,\n",
    "                'Label': info['label'],\n",
    "                'Keywords': ', '.join(info['keywords'][:5]),\n",
    "                'Count': info['count'],\n",
    "                'Percentage': (info['count'] / len(self.code_assignments) * 100) if self.code_assignments else 0,\n",
    "                'Avg Confidence': info['avg_confidence']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(data).sort_values('Count', ascending=False)\n",
    "    \n",
    "    def get_quality_metrics(self):\n",
    "        \"\"\"Calculate quality and reliability metrics.\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Basic statistics\n",
    "        total_assignments = sum(len(codes) for codes in self.code_assignments)\n",
    "        metrics['total_assignments'] = total_assignments\n",
    "        metrics['avg_codes_per_response'] = total_assignments / len(self.code_assignments)\n",
    "        \n",
    "        # Coverage\n",
    "        coded_responses = sum(1 for codes in self.code_assignments if len(codes) > 0)\n",
    "        metrics['coverage_pct'] = (coded_responses / len(self.code_assignments)) * 100\n",
    "        \n",
    "        # Confidence statistics\n",
    "        all_confidences = [conf for confs in self.confidence_scores for conf in confs]\n",
    "        if all_confidences:\n",
    "            metrics['avg_confidence'] = np.mean(all_confidences)\n",
    "            metrics['min_confidence'] = np.min(all_confidences)\n",
    "            metrics['max_confidence'] = np.max(all_confidences)\n",
    "            metrics['std_confidence'] = np.std(all_confidences)\n",
    "        \n",
    "        # Clustering quality (if available)\n",
    "        if self.feature_matrix is not None and hasattr(self.model, 'cluster_centers_'):\n",
    "            labels = self.model.labels_\n",
    "            if len(set(labels)) > 1:\n",
    "                metrics['silhouette_score'] = silhouette_score(\n",
    "                    self.feature_matrix, labels\n",
    "                )\n",
    "                metrics['davies_bouldin_score'] = davies_bouldin_score(\n",
    "                    self.feature_matrix.toarray(), labels\n",
    "                )\n",
    "                metrics['calinski_harabasz_score'] = calinski_harabasz_score(\n",
    "                    self.feature_matrix.toarray(), labels\n",
    "                )\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "print(\"\u2713 MLOpenCoder class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis Results Package\n",
    "\n",
    "Complete results package with all 15 essential outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenCodingResults:\n",
    "    \"\"\"\n",
    "    Comprehensive results package for ML-based open coding.\n",
    "    \n",
    "    Provides all 15 essential outputs:\n",
    "    1. Code Assignments\n",
    "    2. Codebook\n",
    "    3. Frequency Tables\n",
    "    4. Quality Metrics\n",
    "    5. Binary Matrix\n",
    "    6. Representative Quotes\n",
    "    7. Co-occurrence Analysis\n",
    "    8. Descriptive Statistics\n",
    "    9. Segmentation Analysis\n",
    "    10. QA Report\n",
    "    11. Visualizations\n",
    "    12. Exports\n",
    "    13. Documentation\n",
    "    14. Uncoded Responses\n",
    "    15. Executive Summary\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, coder: MLOpenCoder, response_col='response', id_col='response_id'):\n",
    "        self.df = df.copy()\n",
    "        self.coder = coder\n",
    "        self.response_col = response_col\n",
    "        self.id_col = id_col\n",
    "        \n",
    "        # Ensure ID column exists\n",
    "        if id_col not in self.df.columns:\n",
    "            self.df[id_col] = range(1, len(self.df) + 1)\n",
    "        \n",
    "        # Add coding results to dataframe\n",
    "        self.df['assigned_codes'] = coder.code_assignments\n",
    "        self.df['confidence_scores'] = coder.confidence_scores\n",
    "        self.df['num_codes'] = self.df['assigned_codes'].apply(len)\n",
    "        \n",
    "    # OUTPUT 1: Code Assignments\n",
    "    def get_code_assignments(self):\n",
    "        \"\"\"Get complete code assignments with confidence scores.\"\"\"\n",
    "        return self.df[[self.id_col, self.response_col, 'assigned_codes', 'confidence_scores']]\n",
    "    \n",
    "    # OUTPUT 2: Codebook\n",
    "    def get_codebook(self):\n",
    "        \"\"\"Get complete codebook with definitions and examples.\"\"\"\n",
    "        return self.coder.get_codebook_df()\n",
    "    \n",
    "    def get_codebook_detailed(self):\n",
    "        \"\"\"Get detailed codebook with examples.\"\"\"\n",
    "        data = []\n",
    "        for code_id, info in self.coder.codebook.items():\n",
    "            # Get top 3 examples\n",
    "            examples = sorted(info['examples'], key=lambda x: x['confidence'], reverse=True)[:3]\n",
    "            example_text = ' | '.join([f\"{ex['text'][:50]}...\" for ex in examples])\n",
    "            \n",
    "            data.append({\n",
    "                'Code ID': code_id,\n",
    "                'Label': info['label'],\n",
    "                'Definition': f\"Responses about {info['label'].lower()}\",\n",
    "                'Keywords': ', '.join(info['keywords']),\n",
    "                'Examples': example_text if example_text else 'N/A',\n",
    "                'Count': info['count'],\n",
    "                'Percentage': (info['count'] / len(self.df) * 100),\n",
    "                'Avg Confidence': info['avg_confidence']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(data).sort_values('Count', ascending=False)\n",
    "    \n",
    "    # OUTPUT 3: Code Frequency Table\n",
    "    def get_frequency_table(self):\n",
    "        \"\"\"Get code frequency statistics.\"\"\"\n",
    "        freq_data = []\n",
    "        \n",
    "        for code_id, info in self.coder.codebook.items():\n",
    "            count = info['count']\n",
    "            pct = (count / len(self.df)) * 100\n",
    "            \n",
    "            freq_data.append({\n",
    "                'Code': code_id,\n",
    "                'Label': info['label'],\n",
    "                'Count': count,\n",
    "                'Percentage': pct,\n",
    "                'Rank': 0  # Will be filled\n",
    "            })\n",
    "        \n",
    "        freq_df = pd.DataFrame(freq_data).sort_values('Count', ascending=False)\n",
    "        freq_df['Rank'] = range(1, len(freq_df) + 1)\n",
    "        \n",
    "        return freq_df\n",
    "    \n",
    "    # OUTPUT 4: Quality Metrics\n",
    "    def get_quality_metrics(self):\n",
    "        \"\"\"Get comprehensive quality and confidence metrics.\"\"\"\n",
    "        return self.coder.get_quality_metrics()\n",
    "    \n",
    "    # OUTPUT 5: Binary Matrix\n",
    "    def get_binary_matrix(self):\n",
    "        \"\"\"Get binary code matrix for statistical analysis.\"\"\"\n",
    "        # Create binary columns for each code\n",
    "        binary_df = self.df[[self.id_col]].copy()\n",
    "        \n",
    "        for code_id in self.coder.codebook.keys():\n",
    "            binary_df[f'code_{code_id}'] = self.df['assigned_codes'].apply(\n",
    "                lambda codes: 1 if code_id in codes else 0\n",
    "            )\n",
    "        \n",
    "        return binary_df\n",
    "    \n",
    "    # OUTPUT 6: Representative Quotes\n",
    "    def get_representative_quotes(self, top_n=5):\n",
    "        \"\"\"Get top representative quotes for each code.\"\"\"\n",
    "        quotes = {}\n",
    "        \n",
    "        for code_id, info in self.coder.codebook.items():\n",
    "            # Sort examples by confidence\n",
    "            sorted_examples = sorted(\n",
    "                info['examples'],\n",
    "                key=lambda x: x['confidence'],\n",
    "                reverse=True\n",
    "            )[:top_n]\n",
    "            \n",
    "            quotes[code_id] = {\n",
    "                'label': info['label'],\n",
    "                'quotes': [\n",
    "                    {\n",
    "                        'text': ex['text'],\n",
    "                        'confidence': ex['confidence']\n",
    "                    }\n",
    "                    for ex in sorted_examples\n",
    "                ]\n",
    "            }\n",
    "        \n",
    "        return quotes\n",
    "    \n",
    "    # OUTPUT 7: Co-occurrence Analysis\n",
    "    def get_cooccurrence_matrix(self):\n",
    "        \"\"\"Calculate code co-occurrence matrix efficiently.\"\"\"\n",
    "        from itertools import combinations\n",
    "        \n",
    "        codes = list(self.coder.codebook.keys())\n",
    "        n = len(codes)\n",
    "        code_to_idx = {code: i for i, code in enumerate(codes)}\n",
    "        cooccur = np.zeros((n, n))\n",
    "        \n",
    "        # Only iterate over assigned code pairs instead of all possible pairs\n",
    "        for assigned_codes in self.df['assigned_codes']:\n",
    "            # Process pairs of codes that were actually assigned\n",
    "            for code1, code2 in combinations(assigned_codes, 2):\n",
    "                i, j = code_to_idx[code1], code_to_idx[code2]\n",
    "                cooccur[i, j] += 1\n",
    "                cooccur[j, i] += 1  # Symmetric matrix\n",
    "            \n",
    "            # Diagonal: each code co-occurs with itself\n",
    "            for code in assigned_codes:\n",
    "                i = code_to_idx[code]\n",
    "                cooccur[i, i] += 1\n",
    "        \n",
    "        # Create DataFrame\n",
    "        labels = [self.coder.codebook[c]['label'] for c in codes]\n",
    "        cooccur_df = pd.DataFrame(cooccur, index=labels, columns=labels)\n",
    "        \n",
    "        return cooccur_df\n",
    "    \n",
    "    def get_cooccurrence_pairs(self, min_count=2):\n",
    "        \"\"\"Get code pairs that frequently co-occur.\"\"\"\n",
    "        pairs = Counter()\n",
    "        \n",
    "        for assigned_codes in self.df['assigned_codes']:\n",
    "            for i, code1 in enumerate(assigned_codes):\n",
    "                for code2 in assigned_codes[i+1:]:\n",
    "                    pair = tuple(sorted([code1, code2]))\n",
    "                    pairs[pair] += 1\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        pair_data = []\n",
    "        for (code1, code2), count in pairs.most_common():\n",
    "            if count >= min_count:\n",
    "                label1 = self.coder.codebook[code1]['label']\n",
    "                label2 = self.coder.codebook[code2]['label']\n",
    "                \n",
    "                pair_data.append({\n",
    "                    'Code 1': code1,\n",
    "                    'Label 1': label1,\n",
    "                    'Code 2': code2,\n",
    "                    'Label 2': label2,\n",
    "                    'Co-occurrence Count': count,\n",
    "                    'Percentage': (count / len(self.df)) * 100\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(pair_data)\n",
    "    \n",
    "    # OUTPUT 8: Descriptive Statistics\n",
    "    def get_descriptive_stats(self):\n",
    "        \"\"\"Get comprehensive descriptive statistics.\"\"\"\n",
    "        stats = {\n",
    "            'Total Responses': len(self.df),\n",
    "            'Total Codes Defined': len(self.coder.codebook),\n",
    "            'Total Code Assignments': self.df['num_codes'].sum(),\n",
    "            'Mean Codes per Response': self.df['num_codes'].mean(),\n",
    "            'Median Codes per Response': self.df['num_codes'].median(),\n",
    "            'Std Dev Codes per Response': self.df['num_codes'].std(),\n",
    "            'Min Codes per Response': self.df['num_codes'].min(),\n",
    "            'Max Codes per Response': self.df['num_codes'].max(),\n",
    "            'Responses with 0 Codes': (self.df['num_codes'] == 0).sum(),\n",
    "            'Responses with 1+ Codes': (self.df['num_codes'] > 0).sum(),\n",
    "            'Coverage %': ((self.df['num_codes'] > 0).sum() / len(self.df)) * 100\n",
    "        }\n",
    "        \n",
    "        return pd.Series(stats)\n",
    "    \n",
    "    # OUTPUT 9: Segmentation Analysis\n",
    "    def get_segmentation_analysis(self, segment_col):\n",
    "        \"\"\"Analyze code patterns across demographic segments.\"\"\"\n",
    "        if segment_col not in self.df.columns:\n",
    "            return None\n",
    "        \n",
    "        # Get unique segments\n",
    "        segments = self.df[segment_col].unique()\n",
    "        \n",
    "        seg_data = []\n",
    "        for segment in segments:\n",
    "            seg_df = self.df[self.df[segment_col] == segment]\n",
    "            \n",
    "            # Count codes in this segment\n",
    "            for code_id, info in self.coder.codebook.items():\n",
    "                count = sum(1 for codes in seg_df['assigned_codes'] if code_id in codes)\n",
    "                pct = (count / len(seg_df)) * 100 if len(seg_df) > 0 else 0\n",
    "                \n",
    "                seg_data.append({\n",
    "                    'Segment': segment,\n",
    "                    'Code': code_id,\n",
    "                    'Label': info['label'],\n",
    "                    'Count': count,\n",
    "                    'Percentage': pct\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(seg_data)\n",
    "    \n",
    "    # OUTPUT 10: Quality Assurance Report\n",
    "    def get_qa_report(self, sample_size=10):\n",
    "        \"\"\"Generate quality assurance report.\"\"\"\n",
    "        report = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'method': self.coder.method,\n",
    "            'total_responses': len(self.df),\n",
    "            'quality_metrics': self.get_quality_metrics(),\n",
    "            'low_confidence_count': sum(\n",
    "                1 for confs in self.df['confidence_scores']\n",
    "                if any(c < 0.5 for c in confs)\n",
    "            ),\n",
    "            'uncoded_count': (self.df['num_codes'] == 0).sum(),\n",
    "            'multi_coded_count': (self.df['num_codes'] > 1).sum(),\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    # OUTPUT 14: Uncoded/Ambiguous Responses\n",
    "    def get_uncoded_responses(self):\n",
    "        \"\"\"Get responses with no codes assigned.\"\"\"\n",
    "        uncoded = self.df[self.df['num_codes'] == 0]\n",
    "        return uncoded[[self.id_col, self.response_col]]\n",
    "    \n",
    "    def get_low_confidence_responses(self, threshold=0.5):\n",
    "        \"\"\"Get responses with low confidence scores.\"\"\"\n",
    "        low_conf = self.df[\n",
    "            self.df['confidence_scores'].apply(\n",
    "                lambda confs: any(c < threshold for c in confs) if confs else False\n",
    "            )\n",
    "        ]\n",
    "        return low_conf[[self.id_col, self.response_col, 'assigned_codes', 'confidence_scores']]\n",
    "    \n",
    "    def get_ambiguous_responses(self, min_codes=3):\n",
    "        \"\"\"Get responses with many codes (potentially ambiguous).\"\"\"\n",
    "        ambiguous = self.df[self.df['num_codes'] >= min_codes]\n",
    "        return ambiguous[[self.id_col, self.response_col, 'assigned_codes', 'confidence_scores']]\n",
    "\n",
    "print(\"\u2713 OpenCodingResults class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Engine\n",
    "\n",
    "Comprehensive visualization suite for all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodingVisualizer:\n",
    "    \"\"\"Comprehensive visualization engine for open coding results.\"\"\"\n",
    "    \n",
    "    def __init__(self, results: OpenCodingResults):\n",
    "        self.results = results\n",
    "    \n",
    "    def plot_frequency_chart(self, top_n=15):\n",
    "        \"\"\"Bar chart of code frequencies.\"\"\"\n",
    "        freq_df = self.results.get_frequency_table().head(top_n)\n",
    "        \n",
    "        fig = px.bar(\n",
    "            freq_df,\n",
    "            x='Label',\n",
    "            y='Count',\n",
    "            color='Percentage',\n",
    "            title=f'Top {top_n} Code Frequencies',\n",
    "            labels={'Count': 'Number of Responses', 'Label': 'Code'},\n",
    "            color_continuous_scale='Viridis',\n",
    "            text='Count'\n",
    "        )\n",
    "        fig.update_traces(textposition='outside')\n",
    "        fig.update_layout(xaxis_tickangle=-45, height=500)\n",
    "        return fig\n",
    "    \n",
    "    def plot_cooccurrence_heatmap(self):\n",
    "        \"\"\"Heatmap of code co-occurrences.\"\"\"\n",
    "        cooccur_df = self.results.get_cooccurrence_matrix()\n",
    "        \n",
    "        fig = px.imshow(\n",
    "            cooccur_df,\n",
    "            labels=dict(color=\"Co-occurrences\"),\n",
    "            title=\"Code Co-occurrence Matrix\",\n",
    "            color_continuous_scale='YlOrRd',\n",
    "            aspect='auto'\n",
    "        )\n",
    "        fig.update_layout(height=600)\n",
    "        return fig\n",
    "    \n",
    "    def plot_network_diagram(self, min_cooccurrence=2):\n",
    "        \"\"\"Network diagram of code relationships.\"\"\"\n",
    "        if not NETWORKX_AVAILABLE:\n",
    "            print(\"NetworkX not available\")\n",
    "            return None\n",
    "        \n",
    "        # Build network\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add nodes\n",
    "        for code_id, info in self.results.coder.codebook.items():\n",
    "            G.add_node(code_id, label=info['label'], count=info['count'])\n",
    "        \n",
    "        # Add edges from co-occurrences\n",
    "        pairs_df = self.results.get_cooccurrence_pairs(min_count=min_cooccurrence)\n",
    "        for _, row in pairs_df.iterrows():\n",
    "            G.add_edge(\n",
    "                row['Code 1'],\n",
    "                row['Code 2'],\n",
    "                weight=row['Co-occurrence Count']\n",
    "            )\n",
    "        \n",
    "        if len(G.nodes) == 0:\n",
    "            print(\"No nodes to visualize\")\n",
    "            return None\n",
    "        \n",
    "        # Layout\n",
    "        pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "        \n",
    "        # Create edge traces\n",
    "        edge_traces = []\n",
    "        for edge in G.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            weight = G.edges[edge]['weight']\n",
    "            \n",
    "            edge_traces.append(\n",
    "                go.Scatter(\n",
    "                    x=[x0, x1, None],\n",
    "                    y=[y0, y1, None],\n",
    "                    mode='lines',\n",
    "                    line=dict(width=weight, color='#888'),\n",
    "                    hoverinfo='none',\n",
    "                    showlegend=False\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Create node trace\n",
    "        node_x = []\n",
    "        node_y = []\n",
    "        node_text = []\n",
    "        node_size = []\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            x, y = pos[node]\n",
    "            node_x.append(x)\n",
    "            node_y.append(y)\n",
    "            label = G.nodes[node]['label']\n",
    "            count = G.nodes[node]['count']\n",
    "            node_text.append(f\"{label}<br>Count: {count}\")\n",
    "            node_size.append(10 + count * 2)\n",
    "        \n",
    "        node_trace = go.Scatter(\n",
    "            x=node_x,\n",
    "            y=node_y,\n",
    "            mode='markers+text',\n",
    "            hovertext=node_text,\n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                size=node_size,\n",
    "                color='lightblue',\n",
    "                line=dict(width=2, color='darkblue')\n",
    "            ),\n",
    "            text=[G.nodes[node]['label'][:15] for node in G.nodes()],\n",
    "            textposition='top center',\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # Create figure\n",
    "        fig = go.Figure(data=edge_traces + [node_trace])\n",
    "        fig.update_layout(\n",
    "            title='Code Co-occurrence Network',\n",
    "            showlegend=False,\n",
    "            hovermode='closest',\n",
    "            height=700,\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_distribution_histogram(self):\n",
    "        \"\"\"Distribution of codes per response.\"\"\"\n",
    "        fig = px.histogram(\n",
    "            self.results.df,\n",
    "            x='num_codes',\n",
    "            title='Distribution of Codes per Response',\n",
    "            labels={'num_codes': 'Number of Codes', 'count': 'Frequency'},\n",
    "            nbins=max(self.results.df['num_codes'].max(), 5)\n",
    "        )\n",
    "        fig.update_layout(height=400)\n",
    "        return fig\n",
    "    \n",
    "    def plot_wordcloud(self, code_id=None):\n",
    "        \"\"\"Generate word cloud for responses (optionally filtered by code).\"\"\"\n",
    "        if not WORDCLOUD_AVAILABLE:\n",
    "            print(\"WordCloud not available\")\n",
    "            return None\n",
    "        \n",
    "        if code_id:\n",
    "            # Filter by code\n",
    "            filtered = self.results.df[\n",
    "                self.results.df['assigned_codes'].apply(lambda x: code_id in x)\n",
    "            ]\n",
    "            title = f\"Word Cloud - {self.results.coder.codebook[code_id]['label']}\"\n",
    "        else:\n",
    "            filtered = self.results.df\n",
    "            title = \"Word Cloud - All Responses\"\n",
    "        \n",
    "        text = ' '.join(filtered[self.results.response_col].astype(str))\n",
    "        \n",
    "        wordcloud = WordCloud(\n",
    "            width=1000,\n",
    "            height=500,\n",
    "            background_color='white',\n",
    "            colormap='viridis'\n",
    "        ).generate(text)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_confidence_distribution(self):\n",
    "        \"\"\"Distribution of confidence scores.\"\"\"\n",
    "        all_confidences = [\n",
    "            conf\n",
    "            for confs in self.results.df['confidence_scores']\n",
    "            for conf in confs\n",
    "        ]\n",
    "        \n",
    "        fig = px.histogram(\n",
    "            x=all_confidences,\n",
    "            nbins=30,\n",
    "            title='Distribution of Confidence Scores',\n",
    "            labels={'x': 'Confidence Score', 'y': 'Frequency'}\n",
    "        )\n",
    "        fig.update_layout(height=400)\n",
    "        return fig\n",
    "    \n",
    "    def plot_segmentation(self, segment_col, top_codes=5):\n",
    "        \"\"\"Compare code distribution across segments.\"\"\"\n",
    "        seg_df = self.results.get_segmentation_analysis(segment_col)\n",
    "        if seg_df is None:\n",
    "            print(f\"Column '{segment_col}' not found\")\n",
    "            return None\n",
    "        \n",
    "        # Get top codes overall\n",
    "        top_code_ids = self.results.get_frequency_table().head(top_codes)['Code'].tolist()\n",
    "        filtered = seg_df[seg_df['Code'].isin(top_code_ids)]\n",
    "        \n",
    "        fig = px.bar(\n",
    "            filtered,\n",
    "            x='Segment',\n",
    "            y='Percentage',\n",
    "            color='Label',\n",
    "            barmode='group',\n",
    "            title=f'Top {top_codes} Codes by {segment_col}',\n",
    "            labels={'Percentage': 'Percentage of Responses'}\n",
    "        )\n",
    "        fig.update_layout(height=500)\n",
    "        return fig\n",
    "\n",
    "print(\"\u2713 CodingVisualizer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Manager\n",
    "\n",
    "Export results in multiple formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsExporter:\n",
    "    \"\"\"Export coding results in multiple formats.\"\"\"\n",
    "    \n",
    "    def __init__(self, results: OpenCodingResults, output_dir='output'):\n",
    "        self.results = results\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create timestamped subfolder\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.run_dir = self.output_dir / f'coding_run_{timestamp}'\n",
    "        self.run_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def export_all(self):\n",
    "        \"\"\"Export all outputs.\"\"\"\n",
    "        print(f\"Exporting results to: {self.run_dir}\")\n",
    "        \n",
    "        # 1. Code Assignments (CSV)\n",
    "        assignments = self.results.get_code_assignments()\n",
    "        assignments.to_csv(self.run_dir / 'code_assignments.csv', index=False)\n",
    "        print(\"\u2713 Exported code_assignments.csv\")\n",
    "        \n",
    "        # 2. Codebook (CSV)\n",
    "        codebook = self.results.get_codebook_detailed()\n",
    "        codebook.to_csv(self.run_dir / 'codebook.csv', index=False)\n",
    "        print(\"\u2713 Exported codebook.csv\")\n",
    "        \n",
    "        # 3. Frequency Table (CSV)\n",
    "        freq = self.results.get_frequency_table()\n",
    "        freq.to_csv(self.run_dir / 'frequency_table.csv', index=False)\n",
    "        print(\"\u2713 Exported frequency_table.csv\")\n",
    "        \n",
    "        # 4. Quality Metrics (JSON)\n",
    "        metrics = self.results.get_quality_metrics()\n",
    "        with open(self.run_dir / 'quality_metrics.json', 'w') as f:\n",
    "            json.dump(metrics, f, indent=2, default=str)\n",
    "        print(\"\u2713 Exported quality_metrics.json\")\n",
    "        \n",
    "        # 5. Binary Matrix (CSV)\n",
    "        binary = self.results.get_binary_matrix()\n",
    "        binary.to_csv(self.run_dir / 'binary_matrix.csv', index=False)\n",
    "        print(\"\u2713 Exported binary_matrix.csv\")\n",
    "        \n",
    "        # 6. Representative Quotes (JSON)\n",
    "        quotes = self.results.get_representative_quotes()\n",
    "        with open(self.run_dir / 'representative_quotes.json', 'w') as f:\n",
    "            json.dump(quotes, f, indent=2)\n",
    "        print(\"\u2713 Exported representative_quotes.json\")\n",
    "        \n",
    "        # 7. Co-occurrence Matrix (CSV)\n",
    "        cooccur = self.results.get_cooccurrence_matrix()\n",
    "        cooccur.to_csv(self.run_dir / 'cooccurrence_matrix.csv')\n",
    "        print(\"\u2713 Exported cooccurrence_matrix.csv\")\n",
    "        \n",
    "        # Co-occurrence Pairs (CSV)\n",
    "        pairs = self.results.get_cooccurrence_pairs()\n",
    "        pairs.to_csv(self.run_dir / 'cooccurrence_pairs.csv', index=False)\n",
    "        print(\"\u2713 Exported cooccurrence_pairs.csv\")\n",
    "        \n",
    "        # 8. Descriptive Statistics (CSV)\n",
    "        stats = self.results.get_descriptive_stats()\n",
    "        stats.to_csv(self.run_dir / 'descriptive_statistics.csv', header=['Value'])\n",
    "        print(\"\u2713 Exported descriptive_statistics.csv\")\n",
    "        \n",
    "        # 10. QA Report (JSON)\n",
    "        qa = self.results.get_qa_report()\n",
    "        with open(self.run_dir / 'qa_report.json', 'w') as f:\n",
    "            json.dump(qa, f, indent=2, default=str)\n",
    "        print(\"\u2713 Exported qa_report.json\")\n",
    "        \n",
    "        # 14. Uncoded Responses (CSV)\n",
    "        uncoded = self.results.get_uncoded_responses()\n",
    "        uncoded.to_csv(self.run_dir / 'uncoded_responses.csv', index=False)\n",
    "        print(\"\u2713 Exported uncoded_responses.csv\")\n",
    "        \n",
    "        # Low Confidence (CSV)\n",
    "        low_conf = self.results.get_low_confidence_responses()\n",
    "        low_conf.to_csv(self.run_dir / 'low_confidence_responses.csv', index=False)\n",
    "        print(\"\u2713 Exported low_confidence_responses.csv\")\n",
    "        \n",
    "        print(f\"\\n\u2713 All exports complete! Output directory: {self.run_dir}\")\n",
    "        return self.run_dir\n",
    "    \n",
    "    def export_excel(self, filename='coding_results.xlsx'):\n",
    "        \"\"\"Export all results to a single Excel file with multiple sheets.\"\"\"\n",
    "        excel_path = self.run_dir / filename\n",
    "        \n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "            # Code Assignments\n",
    "            self.results.get_code_assignments().to_excel(\n",
    "                writer, sheet_name='Code Assignments', index=False\n",
    "            )\n",
    "            \n",
    "            # Codebook\n",
    "            self.results.get_codebook_detailed().to_excel(\n",
    "                writer, sheet_name='Codebook', index=False\n",
    "            )\n",
    "            \n",
    "            # Frequency Table\n",
    "            self.results.get_frequency_table().to_excel(\n",
    "                writer, sheet_name='Frequency Table', index=False\n",
    "            )\n",
    "            \n",
    "            # Descriptive Stats\n",
    "            self.results.get_descriptive_stats().to_excel(\n",
    "                writer, sheet_name='Statistics'\n",
    "            )\n",
    "            \n",
    "            # Co-occurrence Pairs\n",
    "            self.results.get_cooccurrence_pairs().to_excel(\n",
    "                writer, sheet_name='Co-occurrences', index=False\n",
    "            )\n",
    "            \n",
    "            # Binary Matrix\n",
    "            binary = self.results.get_binary_matrix()\n",
    "            if len(binary.columns) < 16384:  # Excel column limit\n",
    "                binary.to_excel(writer, sheet_name='Binary Matrix', index=False)\n",
    "            \n",
    "            # Uncoded\n",
    "            self.results.get_uncoded_responses().to_excel(\n",
    "                writer, sheet_name='Uncoded Responses', index=False\n",
    "            )\n",
    "        \n",
    "        print(f\"\u2713 Exported comprehensive Excel file: {excel_path}\")\n",
    "        return excel_path\n",
    "\n",
    "print(\"\u2713 ResultsExporter class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Executive Summary Generator\n",
    "\n",
    "OUTPUT 15: Generate executive summary for stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecutiveSummaryGenerator:\n",
    "    \"\"\"Generate executive summary for stakeholders.\"\"\"\n",
    "    \n",
    "    def __init__(self, results: OpenCodingResults):\n",
    "        self.results = results\n",
    "    \n",
    "    def generate(self, top_n_codes=5, top_n_quotes=3):\n",
    "        \"\"\"Generate comprehensive executive summary.\"\"\"\n",
    "        freq_table = self.results.get_frequency_table()\n",
    "        stats = self.results.get_descriptive_stats()\n",
    "        quotes = self.results.get_representative_quotes(top_n=top_n_quotes)\n",
    "        \n",
    "        summary = []\n",
    "        summary.append(\"# EXECUTIVE SUMMARY\")\n",
    "        summary.append(\"=\"*60)\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        # Overview\n",
    "        summary.append(\"## Overview\")\n",
    "        summary.append(f\"- **Total Responses Analyzed:** {stats['Total Responses']:,.0f}\")\n",
    "        summary.append(f\"- **Themes Identified:** {stats['Total Codes Defined']:.0f}\")\n",
    "        summary.append(f\"- **Coverage:** {stats['Coverage %']:.1f}% of responses coded\")\n",
    "        summary.append(f\"- **Average Codes per Response:** {stats['Mean Codes per Response']:.2f}\")\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        # Top Themes\n",
    "        summary.append(f\"## Top {top_n_codes} Themes\")\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        for i, row in freq_table.head(top_n_codes).iterrows():\n",
    "            summary.append(f\"### {row['Rank']}. {row['Label']}\")\n",
    "            summary.append(f\"   - **Frequency:** {row['Count']:,.0f} responses ({row['Percentage']:.1f}%)\")\n",
    "            \n",
    "            # Add sample quote\n",
    "            code_id = row['Code']\n",
    "            if code_id in quotes and quotes[code_id]['quotes']:\n",
    "                top_quote = quotes[code_id]['quotes'][0]\n",
    "                summary.append(f\"   - **Example:** \\\"{top_quote['text'][:150]}...\\\"\")\n",
    "            summary.append(\"\")\n",
    "        \n",
    "        # Key Insights\n",
    "        summary.append(\"## Key Insights\")\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        # Most prevalent theme\n",
    "        top_code = freq_table.iloc[0]\n",
    "        summary.append(\n",
    "            f\"1. **Dominant Theme:** '{top_code['Label']}' appears in \"\n",
    "            f\"{top_code['Percentage']:.1f}% of responses, making it the most \"\n",
    "            f\"prevalent theme in the data.\"\n",
    "        )\n",
    "        \n",
    "        # Coverage insight\n",
    "        if stats['Coverage %'] < 80:\n",
    "            summary.append(\n",
    "                f\"2. **Coverage Note:** {stats['Responses with 0 Codes']:.0f} responses \"\n",
    "                f\"({100 - stats['Coverage %']:.1f}%) were not assigned any codes, \"\n",
    "                f\"suggesting they may require manual review or represent unique perspectives.\"\n",
    "            )\n",
    "        \n",
    "        # Multi-coding insight\n",
    "        multi_coded = self.results.df[self.results.df['num_codes'] > 1]\n",
    "        if len(multi_coded) > 0:\n",
    "            pct_multi = (len(multi_coded) / len(self.results.df)) * 100\n",
    "            summary.append(\n",
    "                f\"3. **Complex Responses:** {len(multi_coded):,.0f} responses ({pct_multi:.1f}%) \"\n",
    "                f\"were assigned multiple codes, indicating nuanced or multifaceted perspectives.\"\n",
    "            )\n",
    "        \n",
    "        summary.append(\"\")\n",
    "        \n",
    "        # Co-occurrence patterns\n",
    "        pairs = self.results.get_cooccurrence_pairs()\n",
    "        if len(pairs) > 0:\n",
    "            summary.append(\"## Common Theme Combinations\")\n",
    "            summary.append(\"\")\n",
    "            for i, row in pairs.head(3).iterrows():\n",
    "                summary.append(\n",
    "                    f\"- **{row['Label 1']}** + **{row['Label 2']}**: \"\n",
    "                    f\"{row['Co-occurrence Count']:.0f} responses ({row['Percentage']:.1f}%)\"\n",
    "                )\n",
    "            summary.append(\"\")\n",
    "        \n",
    "        # Quality metrics\n",
    "        metrics = self.results.get_quality_metrics()\n",
    "        summary.append(\"## Quality Metrics\")\n",
    "        summary.append(\"\")\n",
    "        summary.append(f\"- **Average Confidence:** {metrics.get('avg_confidence', 0):.2f}\")\n",
    "        summary.append(f\"- **Method Used:** {self.results.coder.method.upper()}\")\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        # Recommendations\n",
    "        summary.append(\"## Recommendations\")\n",
    "        summary.append(\"\")\n",
    "        summary.append(\"1. **Focus Areas:** Prioritize initiatives related to the top 3 themes.\")\n",
    "        summary.append(\"2. **Further Investigation:** Review uncoded and low-confidence responses manually.\")\n",
    "        summary.append(\"3. **Segmentation:** Conduct demographic analysis to identify group-specific patterns.\")\n",
    "        summary.append(\"\")\n",
    "        \n",
    "        return \"\\n\".join(summary)\n",
    "    \n",
    "    def save(self, filename='executive_summary.md', output_dir='output'):\n",
    "        \"\"\"Save executive summary to file.\"\"\"\n",
    "        summary_text = self.generate()\n",
    "        \n",
    "        output_path = Path(output_dir) / filename\n",
    "        output_path.parent.mkdir(exist_ok=True)\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(summary_text)\n",
    "        \n",
    "        print(f\"\u2713 Executive summary saved to: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "print(\"\u2713 ExecutiveSummaryGenerator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Analysis: Remote Work Responses\n",
    "\n",
    "Complete end-to-end analysis demonstrating all 15 outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "df = pd.read_csv('data/sample_responses.csv')\n",
    "\n",
    "print(f\"Loaded {len(df)} responses\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few responses:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Train ML Coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit ML coder\n",
    "coder = MLOpenCoder(\n",
    "    n_codes=10,              # Number of themes to discover\n",
    "    method='tfidf_kmeans',   # Algorithm: 'tfidf_kmeans', 'lda', or 'nmf'\n",
    "    min_confidence=0.3       # Minimum confidence threshold\n",
    ")\n",
    "\n",
    "# Fit on responses\n",
    "coder.fit(df['response'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ML CODING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Generate Results Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results package\n",
    "results = OpenCodingResults(df, coder, response_col='response')\n",
    "\n",
    "print(\"\u2713 Results package created\")\n",
    "print(f\"  - {len(results.df)} responses coded\")\n",
    "print(f\"  - {len(results.coder.codebook)} codes identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. OUTPUT 1: Code Assignments\n",
    "\n",
    "Complete code assignments with confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get code assignments\n",
    "assignments = results.get_code_assignments()\n",
    "\n",
    "print(\"CODE ASSIGNMENTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nShowing first 10 of {len(assignments)} responses:\\n\")\n",
    "assignments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. OUTPUT 2: Codebook\n",
    "\n",
    "Complete codebook with definitions and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed codebook\n",
    "codebook = results.get_codebook_detailed()\n",
    "\n",
    "print(\"CODEBOOK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{len(codebook)} codes identified:\\n\")\n",
    "codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. OUTPUT 3: Code Frequency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency table\n",
    "freq_table = results.get_frequency_table()\n",
    "\n",
    "print(\"CODE FREQUENCY TABLE\")\n",
    "print(\"=\"*60)\n",
    "freq_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. OUTPUT 4: Confidence & Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get quality metrics\n",
    "quality_metrics = results.get_quality_metrics()\n",
    "\n",
    "print(\"QUALITY & CONFIDENCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in quality_metrics.items():\n",
    "    print(f\"{metric:.<40} {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. OUTPUT 5: Binary/Multi-Label Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get binary matrix\n",
    "binary_matrix = results.get_binary_matrix()\n",
    "\n",
    "print(\"BINARY CODE MATRIX\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {binary_matrix.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\\n\")\n",
    "binary_matrix.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. OUTPUT 6: Representative Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representative quotes\n",
    "quotes = results.get_representative_quotes(top_n=5)\n",
    "\n",
    "print(\"REPRESENTATIVE QUOTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for code_id, data in list(quotes.items())[:3]:  # Show first 3 codes\n",
    "    print(f\"\\n{code_id}: {data['label']}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, quote in enumerate(data['quotes'], 1):\n",
    "        print(f\"{i}. [{quote['confidence']:.2f}] {quote['text'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. OUTPUT 7: Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get co-occurrence pairs\n",
    "cooccurrence = results.get_cooccurrence_pairs(min_count=2)\n",
    "\n",
    "print(\"CO-OCCURRENCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTop code pairs that appear together:\\n\")\n",
    "cooccurrence.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full co-occurrence matrix\n",
    "cooccur_matrix = results.get_cooccurrence_matrix()\n",
    "\n",
    "print(\"\\nCo-occurrence Matrix:\")\n",
    "cooccur_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. OUTPUT 8: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics\n",
    "desc_stats = results.get_descriptive_stats()\n",
    "\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "desc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. OUTPUT 9: Segmentation Analysis\n",
    "\n",
    "(Optional - requires demographic column in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: If you have a demographic column\n",
    "# Uncomment and modify based on your data\n",
    "\n",
    "# if 'age_group' in df.columns:\n",
    "#     seg_analysis = results.get_segmentation_analysis('age_group')\n",
    "#     print(\"SEGMENTATION ANALYSIS BY AGE GROUP\")\n",
    "#     print(\"=\"*60)\n",
    "#     seg_analysis.head(20)\n",
    "# else:\n",
    "#     print(\"No demographic columns available for segmentation\")\n",
    "\n",
    "print(\"Segmentation analysis requires demographic columns in your data.\")\n",
    "print(\"Example columns: 'age_group', 'gender', 'department', etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. OUTPUT 10: Quality Assurance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get QA report\n",
    "qa_report = results.get_qa_report()\n",
    "\n",
    "print(\"QUALITY ASSURANCE REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTimestamp: {qa_report['timestamp']}\")\n",
    "print(f\"Method: {qa_report['method']}\")\n",
    "print(f\"Total Responses: {qa_report['total_responses']:,}\")\n",
    "print(f\"\\nQuality Issues:\")\n",
    "print(f\"  - Low Confidence Assignments: {qa_report['low_confidence_count']}\")\n",
    "print(f\"  - Uncoded Responses: {qa_report['uncoded_count']}\")\n",
    "print(f\"  - Multi-coded Responses: {qa_report['multi_coded_count']}\")\n",
    "print(f\"\\nQuality Metrics:\")\n",
    "for k, v in qa_report['quality_metrics'].items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. OUTPUT 11: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizer\n",
    "viz = CodingVisualizer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Frequency Chart\n",
    "fig = viz.plot_frequency_chart(top_n=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Co-occurrence Heatmap\n",
    "fig = viz.plot_cooccurrence_heatmap()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Network Diagram\n",
    "fig = viz.plot_network_diagram(min_cooccurrence=2)\n",
    "if fig:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Distribution Histogram\n",
    "fig = viz.plot_distribution_histogram()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Confidence Distribution\n",
    "fig = viz.plot_confidence_distribution()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Word Cloud\n",
    "fig = viz.plot_wordcloud()\n",
    "if fig:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. OUTPUT 14: Uncoded & Ambiguous Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncoded responses\n",
    "uncoded = results.get_uncoded_responses()\n",
    "\n",
    "print(\"UNCODED RESPONSES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total: {len(uncoded)}\")\n",
    "if len(uncoded) > 0:\n",
    "    print(f\"\\nSample:\")\n",
    "    uncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low confidence responses\n",
    "low_conf = results.get_low_confidence_responses(threshold=0.5)\n",
    "\n",
    "print(\"LOW CONFIDENCE RESPONSES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total: {len(low_conf)}\")\n",
    "if len(low_conf) > 0:\n",
    "    print(f\"\\nSample:\")\n",
    "    low_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambiguous (multi-coded) responses\n",
    "ambiguous = results.get_ambiguous_responses(min_codes=3)\n",
    "\n",
    "print(\"AMBIGUOUS RESPONSES (3+ codes)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total: {len(ambiguous)}\")\n",
    "if len(ambiguous) > 0:\n",
    "    print(f\"\\nSample:\")\n",
    "    ambiguous.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. OUTPUT 12: Export All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exporter\n",
    "exporter = ResultsExporter(results, output_dir='output')\n",
    "\n",
    "# Export all formats\n",
    "output_dir = exporter.export_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive Excel file\n",
    "excel_file = exporter.export_excel('ml_coding_results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. OUTPUT 15: Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate executive summary\n",
    "summary_gen = ExecutiveSummaryGenerator(results)\n",
    "summary = summary_gen.generate(top_n_codes=5, top_n_quotes=3)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save executive summary\n",
    "summary_gen.save('executive_summary.md', output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. OUTPUT 13: Method Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate method documentation\n",
    "method_doc = f\"\"\"\n",
    "# ML-Based Open Coding - Method Documentation\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Algorithm Used\n",
    "- **Method:** {coder.method.upper()}\n",
    "- **Number of Codes:** {coder.n_codes}\n",
    "- **Minimum Confidence:** {coder.min_confidence}\n",
    "\n",
    "### Process\n",
    "\n",
    "1. **Text Preprocessing**\n",
    "   - Lowercasing\n",
    "   - Special character removal\n",
    "   - Whitespace normalization\n",
    "\n",
    "2. **Vectorization**\n",
    "   - Vectorizer: {type(coder.vectorizer).__name__}\n",
    "   - Max Features: 1000\n",
    "   - Stop Words: Removed\n",
    "\n",
    "3. **Model Training**\n",
    "   - Algorithm: {type(coder.model).__name__}\n",
    "   - Components/Clusters: {coder.n_codes}\n",
    "\n",
    "4. **Code Assignment**\n",
    "   - Threshold: {coder.min_confidence}\n",
    "   - Multi-label: Yes\n",
    "   - Confidence scoring: Enabled\n",
    "\n",
    "### Quality Assurance\n",
    "\n",
    "- **Coverage:** {quality_metrics.get('coverage_pct', 0):.1f}% of responses coded\n",
    "- **Average Confidence:** {quality_metrics.get('avg_confidence', 0):.3f}\n",
    "- **Validation:** Statistical clustering metrics computed\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. Automated coding may miss nuanced interpretations\n",
    "2. Code labels are auto-generated from keywords\n",
    "3. Confidence scores are probabilistic estimates\n",
    "4. Edge cases and outliers may require manual review\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. Review representative quotes for each code\n",
    "2. Manually validate low-confidence assignments\n",
    "3. Consider human coding for critical decisions\n",
    "4. Use as exploratory tool to complement qualitative analysis\n",
    "\n",
    "### Reproducibility\n",
    "\n",
    "- Random Seed: 42\n",
    "- Python Version: {sys.version}\n",
    "- Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "print(method_doc)\n",
    "\n",
    "# Save method documentation\n",
    "with open(output_dir / 'method_documentation.md', 'w') as f:\n",
    "    f.write(method_doc)\n",
    "\n",
    "print(f\"\\n\u2713 Method documentation saved to: {output_dir / 'method_documentation.md'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Complete Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ML-BASED OPEN CODING - COMPLETE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n\u2713 All 15 Essential Outputs Generated:\\n\")\n",
    "print(\"  1. \u2713 Code Assignments with confidence scores\")\n",
    "print(\"  2. \u2713 Complete Codebook with examples\")\n",
    "print(\"  3. \u2713 Code Frequency Tables\")\n",
    "print(\"  4. \u2713 Quality & Confidence Metrics\")\n",
    "print(\"  5. \u2713 Binary/Multi-Label Matrix\")\n",
    "print(\"  6. \u2713 Representative Quotes\")\n",
    "print(\"  7. \u2713 Co-Occurrence Analysis\")\n",
    "print(\"  8. \u2713 Descriptive Statistics\")\n",
    "print(\"  9. \u2713 Segmentation Analysis (if demographic data available)\")\n",
    "print(\" 10. \u2713 Quality Assurance Report\")\n",
    "print(\" 11. \u2713 Comprehensive Visualizations\")\n",
    "print(\" 12. \u2713 Multiple Export Formats (CSV, Excel, JSON)\")\n",
    "print(\" 13. \u2713 Method Documentation\")\n",
    "print(\" 14. \u2713 Uncoded & Ambiguous Responses\")\n",
    "print(\" 15. \u2713 Executive Summary\")\n",
    "print(f\"\\nOutput Directory: {output_dir}\")\n",
    "print(f\"\\nAnalysis Complete! \ud83c\udf89\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Customization\n",
    "- Adjust `n_codes` parameter to discover more/fewer themes\n",
    "- Try different algorithms: `tfidf_kmeans`, `lda`, or `nmf`\n",
    "- Modify `min_confidence` threshold for stricter/looser coding\n",
    "\n",
    "### Advanced Analysis\n",
    "- Add demographic segmentation if you have group variables\n",
    "- Conduct temporal analysis if you have date fields\n",
    "- Compare multiple datasets or time periods\n",
    "\n",
    "### Validation\n",
    "- Review representative quotes for each code\n",
    "- Manually validate low-confidence assignments\n",
    "- Compare with manual coding (if available)\n",
    "- Use binary matrix for statistical testing\n",
    "\n",
    "### Export & Share\n",
    "- All results exported to timestamped folder\n",
    "- Excel file contains all major outputs\n",
    "- Executive summary ready for stakeholders\n",
    "- Method documentation ensures reproducibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}